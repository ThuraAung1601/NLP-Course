{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-IDF & Word2Vec",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#TD-IDF and Word2Vec representation"
      ],
      "metadata": {
        "id": "fj358PLRrDrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF implementation"
      ],
      "metadata": {
        "id": "9O_sF7f5rSap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aulvLhRusHAO",
        "outputId": "15efbf0f-447b-44d8-bd47-47fa8fe70085"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://doc-08-5g-docs.googleusercontent.com/docs/securesc/e04elm2ufc7fh57280o6p12sgt2ma7f7/gtdvo6m70a65c4dnrb6edde6f24d0ps6/1658036700000/14961254794536018283/12056060788794650457/1F4gXB_YhEKyJrQjtZ5e7UvzapsfhW1lR?e=view&ax=ACxEAsYDvoHKGg3MADwiQERtLTiTCfr569YuWdCLTqYSyLLKmu1T-f_RAD5JstkhrJuKAmjefoVwba8eHBK3JgCAkigfGtv5tJ4pu1YIsJDlYGEgvFjPdxrO7SvswK89kCJw6ufLUw_6pki_X-m0iSNm3pZtDeT4PAy9ukahZq-P3pfTbj30LSCpCIMOcC_wihBDi7f8KzNQxxe3yfavngeVqLeAyijPW035M8CvPG2k5BlT5lIek-0daFO91-1ZVjApHAXLhHAPZZPZIChrD3sIVR5zFsCJeF0IT9M9NvKXZZ6dMFByp0klju-abTD0T4Vhe0sGnL9ClQIHO5AQ_4jcW8U4-np9PWrSbbZbQZr1xDIJTw6iMfI5maKwn6bIs9Eo41jypbdvmnFgSyG7RZqydUgDU-oYzInvoVnczpkcGRZ3J6AXFJM9cqefaxITv__muVX6nvUvXXaflIbJHawXsyGqBk9yFslu-ZDubKzD3mNE8Bx7jVCCQEGF7wEDx85KxJIxymjuqxY1uLTEO-ftSAneCgQmfroSxoCRXEsCIkrwRDOtnQ0zZcunmJO5AR9POIAwg-9OhwjBXNTrX7OLnjcngSOmYyuEhFJG0PwqLLJLbM7FBwUP1eLnYmwsYJ6osuKAFhZF1sRU88MHnqzuZpQjiqaI7L3-0b9O5zjJF-9Z1MKEACe_QkDcuYomSli6eoCbqHRrluE81HGqyHjcpR7bcouwKKLdXkn2u3BysZEjvSvXYNTFQXDs40KTs0zZuGMyGOyNxADeN9YweYOQevXX&uuid=f771d88e-5b24-4a28-b3f0-e2d9caddf858&authuser=0&nonce=9c9lia8ir72gi&user=12056060788794650457&hash=lva9mhhmieldp7fvdg1q84m479k022jk)"
      ],
      "metadata": {
        "id": "nXPotGlAsVuK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading corpus"
      ],
      "metadata": {
        "id": "WBTGRAi7w11H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# return docs and dids\n",
        "def read_corpus(path):\n",
        "  corpus = ''\n",
        "  count = 0\n",
        "  documents = []\n",
        "  dids = []\n",
        "  with open(path,'r',encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "      if line.startswith('.DID') or line.startswith('date') or line.startswith('Cat'):\n",
        "        if line.startswith('.DID'):\n",
        "          if count !=0:\n",
        "             documents.append(corpus)\n",
        "          dids.append(line.split()[1])\n",
        "          corpus = ''\n",
        "          count += 1\n",
        "        continue\n",
        "      corpus += ' ' + line.strip()\n",
        "  documents.append(corpus)\n",
        "  return documents,dids"
      ],
      "metadata": {
        "id": "c1CjkazBshBS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(document):\n",
        "  words = document.split(' ')\n",
        "  words = [w.replace('\\u200c','') for w in words]\n",
        "  # third parameter says remove these character\n",
        "  # first parameter says to replace that argument with the argument in second parameter\n",
        "  translation_table = str.maketrans('', '', \"><.،؟؛:{}\\|+ـ()*&^٪$#❊!/[]=-\")\n",
        "  words = [w.translate(translation_table) for w in words]\n",
        "  words = [w for w in words if w.isalpha()]\n",
        "  return words\n"
      ],
      "metadata": {
        "id": "j-i_YkwOxBiV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents,dids = read_corpus('/content/drive/MyDrive/hamshahri.txt')"
      ],
      "metadata": {
        "id": "F2TtRKirt7vQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# used for idf\n",
        "N = len(documents)"
      ],
      "metadata": {
        "id": "9IiO-rwOydAv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create tf_idf\n",
        "we can create a matrix of words documents but its sparse so we use dictionaries."
      ],
      "metadata": {
        "id": "WjfaYmShyxJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tf_idf_dics(docs,dids):\n",
        "  # term-doc key=term value=dict(doc,number of times a term is in doc)\n",
        "  term_doc = {}\n",
        "  # doc-term key=doc value=dict(term,number of times a term is in doc)\n",
        "  doc_term = {}\n",
        "  for doc,did in zip(docs,dids):\n",
        "    doc_term[did] = {}\n",
        "    for term in clean_text(doc):\n",
        "      if term in doc_term[did]:\n",
        "        doc_term[did][term] +=1\n",
        "      else:\n",
        "        doc_term[did][term] = 1\n",
        "\n",
        "      \n",
        "      if term not in term_doc:\n",
        "        term_doc[term] = {}\n",
        "      if did in term_doc[term]:\n",
        "        term_doc[term][did]+=1\n",
        "      else:\n",
        "        term_doc[term][did] = 1\n",
        "      \n",
        "  return term_doc, doc_term\n"
      ],
      "metadata": {
        "id": "435_-VceykcA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "term_doc, doc_term = create_tf_idf_dics(documents, dids)"
      ],
      "metadata": {
        "id": "0YMOfCEaI_qc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def get_tf_idf(doc,term):\n",
        "  \n",
        "  idf = 0\n",
        "  if len(term_doc[term]) > 0: \n",
        "    idf = math.log(N/ len(term_doc[term]) ,2)\n",
        "\n",
        "  tf = 0\n",
        "  if doc in term_doc[term]:\n",
        "    count = term_doc[term][doc]\n",
        "    if count > 0:\n",
        "      tf = 1 + math.log(count,10)\n",
        "  return tf * idf\n",
        "    "
      ],
      "metadata": {
        "id": "Kr__kudTJwe7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_tf_idf('29', 'تو')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHU2sJShLYpV",
        "outputId": "38b5a809-2b78-4a14-f5a4-34e20ee5bf76"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0793131635624436"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate similarity using cosine formula"
      ],
      "metadata": {
        "id": "9ap25YNMaViJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![cosine formula](https://drive.google.com/file/d/1lgCPHvEWUlmnlr1sCzPgOs6dAFo7rUds/view)"
      ],
      "metadata": {
        "id": "2rnMvrUcSxh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function calculate the similarity of two input doc."
      ],
      "metadata": {
        "id": "5V4otu27R-Uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def similarity_doc(doc_1,doc_2):\n",
        "  if doc_1 in doc_term and doc_2 in doc_term:\n",
        "    doc_product = 0\n",
        "    for term in doc_term[doc_1]:\n",
        "      if term in doc_term[doc_2]:\n",
        "        doc_product += get_tf_idf(doc_1,term) * get_tf_idf(doc_2,term)\n",
        "    length_doc_1 = sum([math.pow(get_tf_idf(doc_1,term),2) for term in doc_term[doc_1]])\n",
        "    length_doc_2 = sum([math.pow(get_tf_idf(doc_2,term),2) for term in doc_term[doc_2]])\n",
        "    return doc_product/(np.sqrt(length_doc_2) * np.sqrt(length_doc_1))\n",
        "\n",
        "  else:\n",
        "    print('Invalid doc number')\n",
        "    return 0"
      ],
      "metadata": {
        "id": "-TbbjtwCUFub"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_doc('29', '25')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf1q3EDmXit2",
        "outputId": "ba235fd7-3ca1-40b0-cdf1-3bb7ac6a620f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9678955789152439"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function calculate the similarity of two input term."
      ],
      "metadata": {
        "id": "3LFhuX09aGHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity_term(term_1,term_2):\n",
        "  if term_1 in term_doc and term_2 in term_doc:\n",
        "    term_product = 0\n",
        "    for doc in term_doc[term_1]:\n",
        "      if doc in term_doc[term_2]:\n",
        "        term_product += get_tf_idf(doc,term_1) * get_tf_idf(doc,term_2)\n",
        "    length_term_1 = sum([math.pow(get_tf_idf(doc,term_1),2) for doc in term_doc[term_1]])\n",
        "    length_term_2 = sum([math.pow(get_tf_idf(doc,term_2),2) for doc in term_doc[term_2]])\n",
        "    return term_product/(np.sqrt(length_term_2) * np.sqrt(length_term_1))\n",
        "\n",
        "  else:\n",
        "    print('Invalid term ')\n",
        "    return 0"
      ],
      "metadata": {
        "id": "da2cVmMaYFmp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_term('عکس', 'تکی')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEbhSBuQYrfq",
        "outputId": "2592152e-f7c8-44ab-94a7-a603b53f5e0a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.991786202274434"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec by Gensim"
      ],
      "metadata": {
        "id": "Cywq8zyWaiGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "5LFdWEEFa1v5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create input for genism model\n",
        "# array of array (each sentence one index and inside that index array of all words of a sentence)\n",
        "sentences = [clean_text(doc) for doc in documents]"
      ],
      "metadata": {
        "id": "LHqmEs68a7bb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sg: Training algorithm: 1 for skip-gram; otherwise CBOW.\n",
        "# min_count: Ignores all words with total frequency lower than this.\n",
        "# window: Maximum distance between the current and predicted word within a sentence.\n",
        "# size: Dimensionality of the word vectors that it create.\n",
        "model = Word2Vec(sentences, min_count=1, size=100, window=10, sg=1)"
      ],
      "metadata": {
        "id": "EM0bn1Q3bhDz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/word2vec.model\")"
      ],
      "metadata": {
        "id": "IWegFXO5ck4e"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec.load(\"/content/drive/MyDrive/word2vec.model\")"
      ],
      "metadata": {
        "id": "TZ6ndByEcqxz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can add as much pair as we want to train model\n",
        "model.train([[\"گیاه\", \"روزنامه\"]], total_examples=1, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc4MSLstcuA2",
        "outputId": "ece9bf56-9fd8-4722-a903-e468a0157758"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert a word to vec\n",
        "vector = model.wv['سلفی']\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsniHHWBc98Z",
        "outputId": "85b8fee0-7018-4fa9-81cd-a4ad53c0cd38"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.5813672e-03,  1.2250592e-02,  3.5644283e-03, -6.1967759e-03,\n",
              "       -2.9380275e-03,  8.4605999e-03, -2.3571576e-03,  4.0819962e-03,\n",
              "       -5.3468300e-03, -3.2291436e-03,  1.3192509e-03,  2.7267467e-03,\n",
              "       -2.9795372e-03,  2.2962620e-03, -6.0755676e-03, -1.9646070e-03,\n",
              "        1.0152564e-02,  1.0037105e-02,  9.7313646e-04,  9.3703670e-03,\n",
              "       -1.2592118e-03, -9.1491302e-04, -7.2104260e-03, -5.2829175e-03,\n",
              "        5.2133501e-03,  8.7235766e-03,  5.4762615e-03, -4.0895962e-03,\n",
              "        2.4464112e-03,  7.3297778e-03,  2.4565714e-03,  7.5403382e-03,\n",
              "        3.9700801e-03, -2.5619094e-03,  8.7603945e-03, -2.3964923e-03,\n",
              "       -5.8297841e-03,  2.9495517e-03,  6.9962344e-03, -5.5420736e-04,\n",
              "        1.5369299e-03,  1.5282126e-03, -8.0993408e-03,  1.8180669e-03,\n",
              "       -3.5012821e-03, -5.7726218e-03,  4.0564132e-03, -6.2498306e-03,\n",
              "       -4.8711358e-05, -6.0710073e-03,  2.9051770e-03, -8.9472355e-03,\n",
              "        8.4255552e-03, -1.2638964e-03,  3.4579483e-04,  1.5046262e-03,\n",
              "        3.1445974e-03,  1.9193825e-03, -9.2064813e-03, -2.0526552e-03,\n",
              "       -2.9822846e-04,  4.8958235e-03, -1.4775697e-03, -1.1053358e-03,\n",
              "       -5.0327834e-03, -9.8792808e-03, -1.3537316e-03, -8.5897623e-03,\n",
              "       -7.4753743e-03, -2.4962330e-03, -3.7225918e-03,  2.5714221e-03,\n",
              "        1.6925057e-03,  8.8780550e-03,  5.7402076e-03, -7.8804875e-03,\n",
              "        4.5649647e-03, -6.0398327e-03, -1.7117072e-03,  1.3278305e-03,\n",
              "        2.1061476e-03, -6.7452532e-03,  5.0171632e-03, -3.1362846e-03,\n",
              "       -3.5668341e-03,  9.1929047e-04, -2.0903153e-03, -6.3465227e-04,\n",
              "       -9.0538478e-03,  6.0336036e-03,  5.2389828e-03, -2.2121780e-03,\n",
              "       -7.3635293e-04,  4.6831779e-03, -1.4097133e-03,  8.3025526e-03,\n",
              "       -9.7683249e-03,  2.1867268e-03,  4.2895065e-03,  4.4345763e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get top n most similar word \n",
        "sims = model.wv.most_similar('سلفی',topn=5)\n",
        "print(sims)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss5coYXAdRT_",
        "outputId": "ec6f734a-89f1-4a17-d2b1-9e7da37b5249"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('تو', 0.8157689571380615), ('من', 0.8078559637069702), ('عه', 0.8005035519599915), ('کنار', 0.7989203929901123), ('برات', 0.789409875869751)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate "
      ],
      "metadata": {
        "id": "HE0PIgIAeVqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(similarity_term('قشنگترین', 'سلفی'))\n",
        "print(similarity_term('سلفی', 'کنار'))\n",
        "print(similarity_term('سلفی', 'منم'))\n",
        "print(similarity_term('سلفی', 'یه'))\n",
        "print(similarity_term('سلفی', 'که'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvQhCOjEeVBZ",
        "outputId": "fd4010d6-a021-4853-8d8c-60abd353b7e6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9842354972667257\n",
            "1.0\n",
            "0.816496580927726\n",
            "1.0\n",
            "0.9183257598178847\n"
          ]
        }
      ]
    }
  ]
}