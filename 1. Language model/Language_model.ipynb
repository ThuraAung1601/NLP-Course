{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Language model"
      ],
      "metadata": {
        "id": "HLpsFX8T-yar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading file"
      ],
      "metadata": {
        "id": "yHfBjo2m-dxl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJbl4sT985wD",
        "outputId": "0003bf10-70b5-44fa-9a1f-65dfd993eb03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Hb58rR--Qjwr21cLK6A29ROp6Uy5pqq8\n",
            "To: /content/train.txt\n",
            "100% 9.87M/9.87M [00:00<00:00, 160MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1Hb58rR--Qjwr21cLK6A29ROp6Uy5pqq8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_lines = []\n",
        "with open('train.txt') as file:\n",
        "  for line in file:\n",
        "    # strip removes any leading (spaces at the beginning) and trailing (spaces at the end) characters (space is the default leading character to remove)\n",
        "    tmp_line = line.strip()\n",
        "    tmp_line = tmp_line.replace('?','')\n",
        "    tmp_line = tmp_line.replace('!','')  \n",
        "    tmp_line = tmp_line.replace('.','')\n",
        "    tmp_line = tmp_line.replace(',','')\n",
        "    all_lines.append(tmp_line)"
      ],
      "metadata": {
        "id": "Z4_LLu-E9DUL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_lines[0])\n",
        "print(all_lines[1])\n",
        "print(len(all_lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbWEsjoj-CKy",
        "outputId": "2515cd97-552f-4bb9-9832-3366ee88d116"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "زانک دل یا اوست یا خود اوست دل\n",
            "عکس هر نقشی نتابد تا ابد\n",
            "188894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unigram language model"
      ],
      "metadata": {
        "id": "6t1v0H6r-mRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function calculates count of each word in corpus and total words in corpus."
      ],
      "metadata": {
        "id": "PQJ3gimNFeNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unigram(corpus):\n",
        "  word_count = {}\n",
        "  total_words = 0\n",
        "  for sentence in corpus:\n",
        "    for word in sentence.split(' '):\n",
        "      total_words += 1\n",
        "      if word in word_count.keys():\n",
        "        word_count[word] +=1\n",
        "      else:\n",
        "        word_count[word] = 1\n",
        "  return word_count, total_words"
      ],
      "metadata": {
        "id": "70b1U4n3-qNN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_count, total_words = unigram(all_lines)"
      ],
      "metadata": {
        "id": "Tzg84AgwAmdL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_count['فتح'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3edSJlgEmap",
        "outputId": "906ca484-d87e-48f3-92e6-f7b17843f2f1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30hMJt0qEwCy",
        "outputId": "5dfa01e1-bbae-4202-b517-fc276fa134e7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1323474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function calculate unigram probability of a word."
      ],
      "metadata": {
        "id": "23TgA9bzFnUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import math\n",
        "def word_unigram_prob(word):\n",
        "  # return math.log((word_count[word] / total_words))\n",
        "  return word_count[word] / total_words"
      ],
      "metadata": {
        "id": "HBkLFX2eE-pJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function calculate unigram probability of a sentence.\n",
        "Because probabilities are so small when we multiply it gets smaller so we can sum log of word unigram probs."
      ],
      "metadata": {
        "id": "Q3Lx46Z3FsHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_unigram_prob(sentence):\n",
        "  sentence_prob = 1\n",
        "  # sentence_prob = 0\n",
        "  for word in sentence.split(' '):\n",
        "    sentence_prob *= word_unigram_prob(word)\n",
        "    # sentence_prob += word_unigram_prob(word)\n",
        "  return sentence_prob"
      ],
      "metadata": {
        "id": "z8l51sByFdG_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob_1 = sentence_unigram_prob('عکس هر نقشی نتابد تا ابد')"
      ],
      "metadata": {
        "id": "VVwECbfLHTUY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob_2 = sentence_unigram_prob('عکس هر محکم نتابد تا ابد')"
      ],
      "metadata": {
        "id": "qIuiahOSHada"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if prob_1>prob_2:\n",
        "  print('prob_1')\n",
        "else:\n",
        "  print('prob_2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvfqE8u0Hg1v",
        "outputId": "d23736d4-d19c-4515-ab97-d6fbdce09725"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prob_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_count['محکم'])\n",
        "print(word_count['نقشی'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MM2EhDCeIOZ3",
        "outputId": "8d162044-49e8-4fd8-acbb-54b0651f3f15"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94\n",
            "45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see the correct sentece is the first sentence but because we are only seeing words and using unigrams and not seeing the connection between words in a sentence the asnwer is wrong."
      ],
      "metadata": {
        "id": "j8-bdKTyHs5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bigram language model"
      ],
      "metadata": {
        "id": "aYeLJnKEIbzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this function we find all previous words of each word in a corpus."
      ],
      "metadata": {
        "id": "0a5k6SPCOhJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bigram(corpus):\n",
        "  word_bigrams = {}\n",
        "  for sentence in corpus:\n",
        "    sentence_words = sentence.split(' ')\n",
        "    for i in range(1,len(sentence_words)):\n",
        "      if sentence_words[i] not in word_bigrams.keys():\n",
        "        word_bigrams[sentence_words[i]] = []\n",
        "      word_bigrams[sentence_words[i]].append(sentence_words[i-1])\n",
        "  return word_bigrams"
      ],
      "metadata": {
        "id": "-x4UmGpFIgYu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_bigrams = bigram(all_lines)"
      ],
      "metadata": {
        "id": "RwG4rrOTOFPt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_bigrams['محکم'])\n",
        "print(len(word_bigrams['محکم']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wxPBuMEORTV",
        "outputId": "14ee05e3-b059-4c52-bfa8-b4c7adf31ad9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['دینست', 'خار', 'که', 'و', 'من', 'من', 'ز', 'گشته', 'حصار', 'و', 'مثالش', 'دو', 'حکم', 'حصار', 'که', 'ساعدان', 'حکم', 'شده', 'اندیشه', 'گاو', 'کرد', '', 'آن', 'گل', 'عشق', 'آنچنان', 'ام', 'رای', 'آباد', 'گامی', 'شاهی', 'ضربتی', 'رایش', 'تو', 'زرهی', 'راکاندران', 'چو', 'نعلش', 'ملک', 'غنچه', 'ضربتی', 'و', 'عشق', 'و', 'شدست', 'معانی', 'بنیاد', 'و', 'من', 'نماید', 'تو', 'تو', 'بد', 'گره', 'و', 'آن', 'من', 'بند', 'اوست', 'سروری', 'را', 'گشت', 'نه', 'سم', 'ضربتی', 'توست', 'هفت', 'که', 'تو', 'چنان', 'بندی', 'عمر', 'عهد', 'کجا', 'کار', 'نهاد', 'عمر', 'بنیاد', 'کار', 'و', 'حصاری', 'ترا', 'بیناد', 'ای', 'تو', 'تقدیر', 'گاو', 'گره', 'وعده', 'اینت', 'عهدها']\n",
            "91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculating p(wi|wi-1) = p(wi,wi-1) / p(wi-1) for each word."
      ],
      "metadata": {
        "id": "MVOStah7RPJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_bigram(word,prev_word):\n",
        "  all_prev_words = word_bigrams[word]\n",
        "  first_word = word_count[prev_word]\n",
        "  count = 0\n",
        "  for prev in all_prev_words:\n",
        "    if prev == prev_word:\n",
        "      count +=1\n",
        "  return count/first_word"
      ],
      "metadata": {
        "id": "IYUrzDAgOsg_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_bigram('تو','محکم')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TVWtsacRYIx",
        "outputId": "84345343-7062-4222-b688-4aa084e11fec"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.010638297872340425"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculating bigram probability for a sentence (for all words in a sentence)."
      ],
      "metadata": {
        "id": "YF2bbqX7TRmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_bigram(sentence):\n",
        "  sentence_words = sentence.split(' ')\n",
        "  prob = word_count[sentence_words[0]]/total_words\n",
        "  for i in range(1, len(sentence_words)):\n",
        "    prob *= word_bigram(sentence_words[i],sentence_words[i-1])\n",
        "  return prob"
      ],
      "metadata": {
        "id": "9ALfVrdNSRP_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob_1 = sentence_bigram('عکس هر نقشی نتابد تا ابد')"
      ],
      "metadata": {
        "id": "G1CODeWRTiEb"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob_2 = sentence_bigram('عکس هر محکم نتابد تا ابد')"
      ],
      "metadata": {
        "id": "K88xrFvfTiEb"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if prob_1>prob_2:\n",
        "  print('prob_1')\n",
        "else:\n",
        "  print('prob_2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ffdc95-be8d-4985-967d-9f8ab6b6dea2",
        "id": "iRnhxcurTiEb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prob_1\n"
          ]
        }
      ]
    }
  ]
}