{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MCI-NLP-Project-Bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc-NQkCziQJ-",
        "outputId": "ca79af7e-d314-4819-cca8-42a6dd0dc4ab"
      },
      "source": [
        "#!pip install tensorflow==2.5.0\n",
        "!pip install transformers\n",
        "\n",
        "!pip install tensorflow_addons\n",
        "import tensorflow_addons as tfa"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.19)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WplMO4ETNl15"
      },
      "source": [
        "PROJECT_PATH='/content/drive/MyDrive/OnlineCourses/MCI-NLP/Final-Prject/deeppavlov_resturants'\n",
        "PROJECT_DATA='/content/drive/MyDrive/OnlineCourses/MCI-NLP/Final-Prject/deeppavlov_resturants/data'"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VUN1JpGODQ9"
      },
      "source": [
        "import json\n",
        "# with open(PROJECT_DATA+\"/ner.json\", 'r') as f:\n",
        "#     NER_dict = json.load(f) \n",
        "    \n",
        "# with open(PROJECT_DATA+\"/intent.json\", 'r') as f:\n",
        "#     INTENT_dict = json.load(f) \n",
        "\n",
        "with open(PROJECT_DATA+\"/ner_intent.json\", 'r') as f:\n",
        "    ner_intent = json.load(f) \n",
        "\n",
        "# counter = 128\n",
        "# new_ner = {}\n",
        "# for t in ner_intent:\n",
        "#     new_ner[t] = ner_intent[t]\n",
        "#     counter = counter-1\n",
        "#     if counter<0:\n",
        "#         break \n",
        "# ner_intent = new_ner"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaO_Sc2fra8I",
        "outputId": "a2333bee-32fe-426e-a26f-32e0137857d5"
      },
      "source": [
        "# NER_INTENT = {k: NER_dict[k] for k in NER_dict if k in INTENT_dict }\n",
        "\n",
        "# INTENT_NER = {k: INTENT_dict[k] for k in INTENT_dict if k in NER_dict}\n",
        "# print(len(NER_INTENT),' ? ',len(INTENT_NER))\n",
        "\n",
        "NER_ITEMS = sorted( set(  [ t2 for t1 in ner_intent for t2 in ner_intent[t1]['NERTAGS']] ),reverse=True )  #'NETTAGS'\n",
        "print(len(NER_ITEMS), NER_ITEMS)\n",
        "\n",
        "INTENT_ITEMS = sorted( set(  [ t2 for t1 in ner_intent for t2 in ner_intent[t1]['INTENTS']] ),reverse=True )  #'NETTAGS'\n",
        "print(len(INTENT_ITEMS),INTENT_ITEMS)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 ['O', 'I-this', 'I-pricerange', 'I-name', 'I-food', 'I-area', 'B-this', 'B-pricerange', 'B-name', 'B-food', 'B-area']\n",
            "27 ['unknown', 'thankyou', 'restart', 'request_pricerange', 'request_postcode', 'request_phone', 'request_food', 'request_area', 'request_addr', 'reqmore', 'reqalts', 'repeat', 'negate', 'inform_this', 'inform_pricerange', 'inform_name', 'inform_food', 'inform_area', 'hello', 'deny_name', 'deny_food', 'confirm_pricerange', 'confirm_food', 'confirm_area', 'bye', 'affirm', 'ack']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofA1Cl3yjAxY"
      },
      "source": [
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"bert-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OahZHBdKlz9C",
        "outputId": "a8ca7987-fde2-4ee7-c8c9-b3cbab86dc89"
      },
      "source": [
        "def encode_texts(tokenizer, texts):\n",
        "    return tokenizer(texts, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "\n",
        "texts = [d for d in ner_intent]\n",
        "tds = encode_texts(tokenizer, texts)\n",
        "tds.keys()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RBQLM6AmzK8"
      },
      "source": [
        "encoded_texts = tds"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Op4zGEvrL5J",
        "outputId": "bf660cc2-b7e9-4de3-c97a-6a4882a5eb51"
      },
      "source": [
        "intent_map = dict() # index -> intent\n",
        "for idx, ui in enumerate(INTENT_ITEMS):\n",
        "    intent_map[ui] = idx\n",
        "intent_map"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ack': 26,\n",
              " 'affirm': 25,\n",
              " 'bye': 24,\n",
              " 'confirm_area': 23,\n",
              " 'confirm_food': 22,\n",
              " 'confirm_pricerange': 21,\n",
              " 'deny_food': 20,\n",
              " 'deny_name': 19,\n",
              " 'hello': 18,\n",
              " 'inform_area': 17,\n",
              " 'inform_food': 16,\n",
              " 'inform_name': 15,\n",
              " 'inform_pricerange': 14,\n",
              " 'inform_this': 13,\n",
              " 'negate': 12,\n",
              " 'repeat': 11,\n",
              " 'reqalts': 10,\n",
              " 'reqmore': 9,\n",
              " 'request_addr': 8,\n",
              " 'request_area': 7,\n",
              " 'request_food': 6,\n",
              " 'request_phone': 5,\n",
              " 'request_postcode': 4,\n",
              " 'request_pricerange': 3,\n",
              " 'restart': 2,\n",
              " 'thankyou': 1,\n",
              " 'unknown': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEeEeeBfsCsd",
        "outputId": "bf7236ea-9242-48cd-ff2b-a1b78e9c58fb"
      },
      "source": [
        "# map to train_data values\n",
        "# def encode_intents(intents, intent_map):\n",
        "#     encoded = []\n",
        "#     for i in intents:\n",
        "#         encoded.append(intent_map[i])\n",
        "#     # convert to tf tensor\n",
        "#     return tf.convert_to_tensor(encoded, dtype=\"int32\")\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "# # map to train_data values\n",
        "def encode_intents(intents, intent_map):\n",
        "    encoded = np.zeros((len(intents),len(intent_map)))\n",
        "    for idx,intnt in enumerate(intents):\n",
        "        encoded[ idx, [intent_map[i] for i in intnt]] = 1\n",
        "    # convert to tf tensor\n",
        "\n",
        "    return tf.convert_to_tensor(encoded, dtype=\"int32\")\n",
        "\n",
        "encoded_intents = encode_intents([ ner_intent[t]['INTENTS'] for t in ner_intent], intent_map)\n",
        "encoded_intents"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1933, 27), dtype=int32, numpy=\n",
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 1, 0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYHo5Y706-kX",
        "outputId": "fae57311-f39d-4f96-f31a-91ff8e6065d1"
      },
      "source": [
        "np.argmax(encoded_intents[0]),ner_intent[next(iter(ner_intent))]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14,\n",
              " {'INTENTS': ['inform_pricerange'],\n",
              "  'NERTAGS': ['B-pricerange', 'O'],\n",
              "  'NERVLAS': {'pricerange': 'cheap'},\n",
              "  'TEXT': ['cheap', 'restaurant']})"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Agm4uQYptAIj",
        "outputId": "dd341d48-369e-4531-831b-93d95f3f8300"
      },
      "source": [
        "slot_map = dict() # slot -> index\n",
        "for idx, us in enumerate(NER_ITEMS):\n",
        "    slot_map[us] = idx\n",
        "slot_map"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-area': 10,\n",
              " 'B-food': 9,\n",
              " 'B-name': 8,\n",
              " 'B-pricerange': 7,\n",
              " 'B-this': 6,\n",
              " 'I-area': 5,\n",
              " 'I-food': 4,\n",
              " 'I-name': 3,\n",
              " 'I-pricerange': 2,\n",
              " 'I-this': 1,\n",
              " 'O': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTa2taFftPHO"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# find the max encoded test length\n",
        "# tokenizer pads all texts to same length anyway so\n",
        "# just get the length of the first one's input_ids\n",
        "#max_len = len(encoded_texts[\"input_ids\"][0])\n",
        "max_len = max([len(x) for x in encoded_texts[\"input_ids\"]])\n",
        "\n",
        "def encode_slots(all_slots, all_texts, \n",
        "                 toknizer, slot_map, max_len=max_len):\n",
        "    encoded_slots = np.zeros(shape=(len(all_texts), max_len), dtype=np.int32)\n",
        "    \n",
        "    for idx, text in enumerate(all_texts):\n",
        "        enc = [] # for this idx, to be added at the end to encoded_slots\n",
        "        \n",
        "        # slot names for this idx\n",
        "        slot_names = all_slots[idx]\n",
        "        \n",
        "        # raw word tokens\n",
        "        # not using bert for this block because bert uses\n",
        "        # a wordpiece tokenizer which will make \n",
        "        # the slot label to word mapping\n",
        "        # difficult\n",
        "        raw_tokens = text.split()\n",
        "\n",
        "        # words or slot_values associated with a certain\n",
        "        # slot_name are contained in the values of the\n",
        "        # dict slots_names\n",
        "        # now this becomes a two way lookup\n",
        "        # first we check if a word belongs to any\n",
        "        # slot label or not and then we add the value from\n",
        "        # slot map to encoded for that word\n",
        "        for rt,rt_slot_name in zip(raw_tokens,slot_names):\n",
        "            # use bert tokenizer\n",
        "            # to get wordpiece tokens\n",
        "            bert_tokens = tokenizer.tokenize(rt)\n",
        "            \n",
        "            # find the slot name for a token\n",
        "            #rt_slot_name = get_slot_from_word(rt, slot_names)\n",
        "            #rt_slot_name = get_slot_from_word(rt, slot_names) Moved to for and ziped\n",
        "            if rt_slot_name is not None:\n",
        "                # fill with the slot_map value for all ber tokens for rt\n",
        "                enc.append(slot_map[rt_slot_name])\n",
        "                enc.extend([slot_map[rt_slot_name]] * (len(bert_tokens) - 1))\n",
        "\n",
        "            else:\n",
        "                # rt is not associated with any slot name\n",
        "                enc.append(0)\n",
        "                \n",
        "        \n",
        "        # now add to encoded_slots\n",
        "        # ignore the first and the last elements\n",
        "        # in encoded text as they're special chars\n",
        "        encoded_slots[idx, 1:len(enc)+1] = enc\n",
        "    \n",
        "    return encoded_slots\n",
        "    "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POYbnuUCV4q0"
      },
      "source": [
        "# all_slots = [td.slots for td in train_data]\n",
        "# all_texts = [td.text for td in train_data]\n",
        "\n",
        "\n",
        "all_slots = [ s['NERTAGS'] for t,s in ner_intent.items() ]\n",
        "all_texts = [ t for t in ner_intent ]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zRFtVlaV-JZ",
        "outputId": "e8427066-af24-4163-fac3-595ac4e6c950"
      },
      "source": [
        "encoded_slots = encode_slots(all_slots, all_texts, tokenizer, slot_map)\n",
        "encoded_slots[2],all_slots[2],all_texts[2]\n",
        "encoded_slots.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1933, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Zk0TYJJm_F4"
      },
      "source": [
        "# **Classifier Model** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdcOOKIjV-g6"
      },
      "source": [
        "from transformers import TFBertModel\n",
        "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "\n",
        "class JointIntentAndSlotFillingModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, intent_num_labels=None, slot_num_labels=None,\n",
        "                 model_name=model_name, dropout_prob=0.1):\n",
        "        super().__init__(name=\"joint_intent_slot\")\n",
        "        self.bert = TFBertModel.from_pretrained(model_name)\n",
        "        self.dropout = Dropout(dropout_prob)\n",
        "        # self.intent_classifier = Dense(intent_num_labels,\n",
        "        #                                name=\"intent_classifier\")\n",
        "\n",
        "        self.intent_classifier = Dense(intent_num_labels, activation='sigmoid',\n",
        "                                       name=\"intent_classifier\")\n",
        "\n",
        "        self.slot_classifier = Dense(slot_num_labels,\n",
        "                                     name=\"slot_classifier\")\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        # two outputs from BERT\n",
        "        trained_bert = self.bert(inputs, **kwargs)\n",
        "        pooled_output = trained_bert.pooler_output\n",
        "        sequence_output = trained_bert.last_hidden_state\n",
        "        \n",
        "        # sequence_output will be used for slot_filling / classification\n",
        "        sequence_output = self.dropout(sequence_output,\n",
        "                                       training=kwargs.get(\"training\", False))\n",
        "        slot_logits = self.slot_classifier(sequence_output)\n",
        "\n",
        "        # pooled_output for intent classification\n",
        "        pooled_output = self.dropout(pooled_output,\n",
        "                                     training=kwargs.get(\"training\", False))\n",
        "        intent_logits = self.intent_classifier(pooled_output)\n",
        "        return slot_logits, intent_logits\n",
        "        #return {'slot': slot_logits,'intent': intent_logits} "
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Orx-7XHTnpFK",
        "outputId": "b40995d6-fa36-42ae-da3c-6add72d9d0bf"
      },
      "source": [
        "joint_model = JointIntentAndSlotFillingModel(\n",
        "    intent_num_labels=len(intent_map), slot_num_labels=len(slot_map))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxiXeaVpoACV"
      },
      "source": [
        "#https://towardsdatascience.com/multi-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72\n",
        "@tf.function\n",
        "def macro_soft_f1(y, y_hat):\n",
        "    \"\"\"Compute the macro soft F1-score as a cost (average 1 - soft-F1 across all labels).\n",
        "    Use probability values instead of binary predictions.\n",
        "    \n",
        "    Args:\n",
        "        y (int32 Tensor): targets array of shape (BATCH_SIZE, N_LABELS)\n",
        "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
        "        \n",
        "    Returns:\n",
        "        cost (scalar Tensor): value of the cost function for the batch\n",
        "    \"\"\"\n",
        "    y = tf.cast(y, tf.float32)\n",
        "    y_hat = tf.cast(y_hat, tf.float32)\n",
        "    tp = tf.reduce_sum(y_hat * y, axis=0)\n",
        "    fp = tf.reduce_sum(y_hat * (1 - y), axis=0)\n",
        "    fn = tf.reduce_sum((1 - y_hat) * y, axis=0)\n",
        "    soft_f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
        "    cost = 1 - soft_f1 # reduce 1 - soft-f1 in order to increase soft-f1\n",
        "    macro_cost = tf.reduce_mean(cost) # average on all labels\n",
        "    return macro_cost\n",
        "\n",
        "@tf.function\n",
        "def macro_f1(y, y_hat, thresh=0.5):\n",
        "    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n",
        "    \n",
        "    Args:\n",
        "        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n",
        "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
        "        thresh: probability value above which we predict positive\n",
        "        \n",
        "    Returns:\n",
        "        macro_f1 (scalar Tensor): value of macro F1 for the batch\n",
        "    \"\"\"\n",
        "    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n",
        "    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
        "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
        "    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n",
        "    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
        "    macro_f1 = tf.reduce_mean(f1)\n",
        "    return macro_f1"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7zcQQ16qLz-"
      },
      "source": [
        "# opt = Adam(learning_rate=3e-5, epsilon=1e-08)\n",
        "\n",
        "# # two outputs, one for slots, another for intents\n",
        "# # we have to fine tune for both\n",
        "# losses = [SparseCategoricalCrossentropy(from_logits=True),\n",
        "#           SparseCategoricalCrossentropy(from_logits=True)]\n",
        "\n",
        "# metrics = [SparseCategoricalAccuracy(\"accuracy\")]\n",
        "# # compile model\n",
        "# joint_model.compile(optimizer=opt, loss=losses, metrics=metrics)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm07I6_dD1sk",
        "outputId": "2ad0106d-0f1c-45ea-c030-94d21392ddf1"
      },
      "source": [
        "encoded_slots.shape[1], encoded_intents.shape[1]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22, 27)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBZsPU_vls8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "512199fc-83bb-43a1-84e1-52ce89989794"
      },
      "source": [
        "categorcial_slots = tf.keras.utils.to_categorical(encoded_slots, num_classes=len(slot_map))\n",
        "categorcial_slots.shape, categorcial_slots.shape[-1]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1933, 22, 11), 11)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OamjvxucecOR"
      },
      "source": [
        "class MacroF1(tf.keras.metrics.Metric):\n",
        "\n",
        "  def __init__(self, name='MacroF1', **kwargs):\n",
        "    super(MacroF1, self).__init__(name=name, **kwargs)\n",
        "    self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    thresh = 0.5\n",
        "    y_hat =  tf.cast(tf.reshape(y_pred, [-1,11]),tf.float32)\n",
        "   \n",
        "    y2 = tf.cast(y_true, tf.float32)\n",
        "    y2 = tf.keras.utils.to_categorical(y2, num_classes=11)\n",
        "    y2 = tf.reshape(y2,[-1])\n",
        "    #oh_labels = tf.cast(tf.one_hot(tf.cast(labels, tf.int32), num_classes), dtype=labels.dtype)\n",
        "    #print(y)\n",
        "    #y2 = tf.cast(tf.one_hot(tf.cast(y2, tf.int32), 11), dtype=tf.int32)\n",
        "    y =  tf.cast(y2 , tf.float32)\n",
        "\n",
        "    print(y.shape, y_hat)\n",
        "    print(y.shape, y_hat)\n",
        "    print(y.shape, y_hat)\n",
        "    print(y.shape, y_hat)\n",
        "    print(y.shape, y_hat)\n",
        "    print(y.shape, y_hat)\n",
        "\n",
        "    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n",
        "    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
        "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
        "    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n",
        "    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
        "    macro_f1 = tf.reduce_mean(f1)\n",
        "\n",
        "  def result(self):\n",
        "    return self.true_positives"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSFCYtZkvwyH"
      },
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "class MY_F1Score(tfa.metrics.FBetaScore):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes: 11,\n",
        "        average = None,\n",
        "        threshold = None,\n",
        "        name = \"MY_F1Score\",\n",
        "        dtype = None,\n",
        "    ):\n",
        "        super().__init__(num_classes, average, 1.0, threshold, name=name, dtype=dtype)\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        del base_config[\"beta\"]\n",
        "        return base_config\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):   \n",
        "        #print(y_true,y_pred) \n",
        "        #y_true_ = tf.keras.utils.to_categorical(y_true, num_classes=11)\n",
        "        y_true_ = tf.constant(tf.reshape(y_true,[-1,y_true.shape[-1]])   )\n",
        "        y_pred_ = tf.constant(tf.reshape(y_pred,[-1,y_pred.shape[-1]])   )\n",
        "        #print(y_true_,y_pred_) \n",
        " \n",
        "        super().update_state(y_true_, y_pred_, sample_weight=None)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqHpBpgRtj63"
      },
      "source": [
        "opt = Adam(learning_rate=3e-5, epsilon=1e-08)\n",
        "\n",
        "# two outputs, one for slots, another for intents\n",
        "# we have to fine tune for both\n",
        "# losses = [SparseCategoricalCrossentropy(from_logits=True),\n",
        "#           'binary_crossentropy'\n",
        "#           #macro_soft_f1\n",
        "#           ]\n",
        "\n",
        "losses = [CategoricalCrossentropy(from_logits=True),\n",
        "          'binary_crossentropy'\n",
        "          #macro_soft_f1\n",
        "          ]\n",
        "                    \n",
        "# losses = {'slot': CategoricalCrossentropy(from_logits=True),'intent': 'binary_crossentropy'}\n",
        "\n",
        "#from tensorflow_addons import metrics\n",
        "#metric1 = tfa.metrics.F1Score(num_classes=encoded_slots.shape[1], average = 'macro', threshold=0.7, name='m1')\n",
        "metric2 = tfa.metrics.F1Score(num_classes=encoded_intents.shape[1], average = 'macro', threshold=0.7, name='m2')\n",
        "\n",
        "\n",
        "#metrics = ['accuracy']\n",
        "#metrics = [ metric1, metric2]\n",
        "# metric1 = MY_F1Score(num_classes=11, average = 'micro', threshold=0.7, name='m1')\n",
        "# metrics = {'slot':metric1, \"'intent'\":metric2} \n",
        "metrics = [ MY_F1Score(num_classes=11, average = 'micro', threshold=0.7, name='m1')]\n",
        "\n",
        "# compile model\n",
        "joint_model.compile(optimizer=opt, loss=losses, loss_weights = [1,3], metrics=metrics)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQnDTlBAt8IY",
        "outputId": "0f8a1f56-2cd6-4c68-de57-adfd8d940abd"
      },
      "source": [
        "x = {\"input_ids\": encoded_texts[\"input_ids\"], \"token_type_ids\": encoded_texts[\"token_type_ids\"],  \"attention_mask\": encoded_texts[\"attention_mask\"]}\n",
        "\n",
        "#history = joint_model.fit(x, (encoded_slots, encoded_intents), epochs=1, batch_size=32, shuffle=True)\n",
        "history = joint_model.fit(x, (categorcial_slots, encoded_intents), epochs=6, batch_size=32, shuffle=True)\n",
        "#history = joint_model.fit(x, {'slot': categorcial_slots,'intent': encoded_intents}, epochs=1, batch_size=32, shuffle=True)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4212: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "61/61 [==============================] - 35s 566ms/step - loss: 1.1489 - output_1_loss: 0.2468 - output_2_loss: 0.3007 - output_1_m1: 0.6716 - output_2_m1: 0.0422\n",
            "Epoch 2/6\n",
            "61/61 [==============================] - 34s 559ms/step - loss: 0.3524 - output_1_loss: 0.0356 - output_2_loss: 0.1056 - output_1_m1: 0.7935 - output_2_m1: 0.5108\n",
            "Epoch 3/6\n",
            "61/61 [==============================] - 34s 564ms/step - loss: 0.2274 - output_1_loss: 0.0194 - output_2_loss: 0.0693 - output_1_m1: 0.7955 - output_2_m1: 0.7562\n",
            "Epoch 4/6\n",
            "61/61 [==============================] - 34s 564ms/step - loss: 0.1655 - output_1_loss: 0.0113 - output_2_loss: 0.0514 - output_1_m1: 0.8006 - output_2_m1: 0.8297\n",
            "Epoch 5/6\n",
            "61/61 [==============================] - 34s 554ms/step - loss: 0.1238 - output_1_loss: 0.0077 - output_2_loss: 0.0387 - output_1_m1: 0.8087 - output_2_m1: 0.8768\n",
            "Epoch 6/6\n",
            "61/61 [==============================] - 35s 566ms/step - loss: 0.0979 - output_1_loss: 0.0057 - output_2_loss: 0.0307 - output_1_m1: 0.8127 - output_2_m1: 0.9097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y840riuFyRqS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44e05b05-7e81-4974-b0c6-dd7bd96e1f0d"
      },
      "source": [
        "res = joint_model.predict(x)\n",
        "res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4212: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr8zxOpvxT4B"
      },
      "source": [
        "# test = MY_F1Score(num_classes=11, average = 'macro', threshold=0.7, name='m1')\n",
        "\n",
        "# test.update_state(encoded_slots,res[0])\n",
        "# test.result()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMdZwou5X6Rn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f70b294-83bc-42c4-8c0a-7d98ca912e52"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.random.random((10))\n",
        "print(a,np.nonzero(a>0.5)[0])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.81436776 0.39760391 0.28431828 0.9049492  0.50967494 0.3507657\n",
            " 0.51212164 0.60843194 0.19609155 0.40180292] [0 3 4 6 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "870Fi-RgKVth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "901ac58d-8ea5-4ccf-a01f-2b12ae6058db"
      },
      "source": [
        "def map2cat(t):\n",
        "    return t.replace(\"B-\", \"\").replace(\"I-\", \"\") \n",
        "\n",
        "def nlu(text, tokenizer, model, intent_names, slot_names):\n",
        "    inputs = tf.constant(tokenizer.encode(text))[None, :]  # batch_size = 1\n",
        "    outputs = model(inputs)\n",
        "    #print(outputs)\n",
        "    slot_logits, intent_logits = outputs\n",
        "\n",
        "    slot_ids = slot_logits.numpy().argmax(axis=-1)[0, :]\n",
        "    #intent_id = intent_logits.numpy().argmax(axis=-1)[0]\n",
        "    intent_ids = np.nonzero(intent_logits.numpy()>0.8)[1]\n",
        "    #print(intent_logits,np.nonzero(intent_logits.numpy()>0.5))\n",
        "\n",
        "    #info = {\"intent\": intent_names[intent_id], \"slots\": {}}\n",
        "    info = {\"intent\": [intent_names[intent_id] for intent_id in intent_ids], \"slots\": {}}\n",
        "    \n",
        "    out_dict = {}\n",
        "    # get all slot names and add to out_dict as keys\n",
        "    predicted_slots = set([slot_names[s] for s in slot_ids if s != 0])\n",
        "\n",
        "    #merge slots\n",
        "    predicted_slots = set([ map2cat(t) for t in predicted_slots])\n",
        "    #print(predicted_slots)\n",
        "    for ps in predicted_slots:\n",
        "      out_dict[ps] = []\n",
        "\n",
        "    # check if the text starts with a small letter\n",
        "    if text[0].islower():\n",
        "      tokens = tokenizer.tokenize(text, add_special_tokens=True)\n",
        "    else:\n",
        "      tokens = tokenizer.tokenize(text)\n",
        "    for token, slot_id in zip(tokens, slot_ids):\n",
        "        # add all to out_dict\n",
        "        #slot_name = slot_names[slot_id]\n",
        "        slot_name = map2cat(slot_names[slot_id])\n",
        "\n",
        "        if slot_name == \"O\":\n",
        "            continue\n",
        "\n",
        "        # collect tokens\n",
        "        collected_tokens = [token]\n",
        "        idx = tokens.index(token)\n",
        "\n",
        "        # see if it starts with ##\n",
        "        # then it belongs to the previous token\n",
        "        if token.startswith(\"##\"):\n",
        "          # check if the token already exists or not\n",
        "          if tokens[idx - 1] not in out_dict[slot_name]:\n",
        "            collected_tokens.insert(0, tokens[idx - 1])\n",
        "\n",
        "        # add collected tokens to slots\n",
        "        out_dict[slot_name].extend(collected_tokens)\n",
        "\n",
        "    # process out_dict\n",
        "    for slot_name in out_dict:\n",
        "        tokens = out_dict[slot_name]\n",
        "        slot_value = tokenizer.convert_tokens_to_string(tokens)\n",
        "\n",
        "        info[\"slots\"][slot_name] = slot_value.strip()\n",
        "\n",
        "    return info\n",
        "\n",
        "t_itrator=iter(ner_intent)\n",
        "for i in range(3):\n",
        "    tkey = next(t_itrator)\n",
        "    print(tkey, nlu(tkey, tokenizer, joint_model, INTENT_ITEMS, NER_ITEMS), ner_intent[tkey]['INTENTS'], ner_intent[tkey]['NERVLAS'])\n",
        "    print()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cheap restaurant {'intent': ['inform_pricerange'], 'slots': {'pricerange': 'cheap'}} ['inform_pricerange'] {'pricerange': 'cheap'}\n",
            "\n",
            "any {'intent': [], 'slots': {}} ['inform_this'] {}\n",
            "\n",
            "south {'intent': ['inform_area'], 'slots': {'area': 'south'}} ['inform_area'] {'area': 'south'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBJsZ44nKds9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23570aa1-8344-4158-da21-408d8e4e840f"
      },
      "source": [
        "nlu(\"i am looking for a fast food\", tokenizer, joint_model, \n",
        "    INTENT_ITEMS, NER_ITEMS)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'intent': ['inform_food'], 'slots': {'food': 'fast'}}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBvRKEd9LaK4"
      },
      "source": [
        "# State tracker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUpE8vRWo0DI"
      },
      "source": [
        "#load templates\n",
        "def load_templates():\n",
        "    templates = {}\n",
        "    with open(PROJECT_DATA+\"/simple-dstc2-templates.txt\", 'r') as f:\n",
        "        Lines = f.readlines()\n",
        "    for line in Lines:\n",
        "        key, val = line.split(\"\\t\")\n",
        "        templates[key] = val.strip()\n",
        "    \n",
        "    return templates\n",
        "\n",
        "templates = load_templates()\n",
        "#templates"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-1VskMpmM-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4aed8e6-f742-4efe-c68d-91c370ae0870"
      },
      "source": [
        "act_map = dict() # slot -> index\n",
        "for idx, us in enumerate(templates.keys()):\n",
        "    act_map[us] = idx\n",
        "act_map"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'api_call': 0,\n",
              " 'bye': 1,\n",
              " 'canthear': 2,\n",
              " 'canthelp_area': 3,\n",
              " 'canthelp_area_food': 4,\n",
              " 'canthelp_area_food_pricerange': 5,\n",
              " 'canthelp_area_pricerange': 6,\n",
              " 'canthelp_food': 7,\n",
              " 'canthelp_food_pricerange': 8,\n",
              " 'confirm-domain': 9,\n",
              " 'expl-conf_area': 10,\n",
              " 'expl-conf_food': 11,\n",
              " 'expl-conf_pricerange': 12,\n",
              " 'impl-conf_area+impl-conf_pricerange+request_food': 13,\n",
              " 'impl-conf_food+impl-conf_pricerange+request_area': 14,\n",
              " 'impl-conf_food+request_area': 15,\n",
              " 'inform_addr+inform_food+offer_name': 16,\n",
              " 'inform_addr+inform_phone+inform_pricerange+offer_name': 17,\n",
              " 'inform_addr+inform_phone+offer_name': 18,\n",
              " 'inform_addr+inform_postcode+offer_name': 19,\n",
              " 'inform_addr+inform_pricerange+offer_name': 20,\n",
              " 'inform_addr+offer_name': 21,\n",
              " 'inform_area+inform_food+inform_pricerange+offer_name': 22,\n",
              " 'inform_area+inform_food+offer_name': 23,\n",
              " 'inform_area+inform_phone+offer_name': 24,\n",
              " 'inform_area+inform_postcode+offer_name': 25,\n",
              " 'inform_area+inform_pricerange+offer_name': 26,\n",
              " 'inform_area+offer_name': 27,\n",
              " 'inform_food+inform_pricerange+offer_name': 28,\n",
              " 'inform_food+offer_name': 29,\n",
              " 'inform_phone+inform_postcode+offer_name': 30,\n",
              " 'inform_phone+inform_pricerange+offer_name': 31,\n",
              " 'inform_phone+offer_name': 32,\n",
              " 'inform_postcode+inform_pricerange+offer_name': 33,\n",
              " 'inform_postcode+offer_name': 34,\n",
              " 'inform_pricerange+offer_name': 35,\n",
              " 'offer_name': 36,\n",
              " 'repeat': 37,\n",
              " 'reqmore': 38,\n",
              " 'request_area': 39,\n",
              " 'request_food': 40,\n",
              " 'request_pricerange': 41,\n",
              " 'select_area': 42,\n",
              " 'select_food': 43,\n",
              " 'select_pricerange': 44,\n",
              " 'welcomemsg': 45}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tDEdklYAGBh"
      },
      "source": [
        "import json \n",
        "\n",
        "import json\n",
        "with open(PROJECT_DATA+\"/slot_vals.json\", 'r') as f:\n",
        "    slot_vals = json.load(f)\n",
        "\n",
        "def get_real_val(k,v):\n",
        "    search_domain = slot_vals[k]\n",
        "    for t in search_domain:\n",
        "        if v in search_domain[t]:\n",
        "            return t\n",
        "    return \"'\"+v        \n",
        "    \n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLfn1zLyjSNE"
      },
      "source": [
        "import json\n",
        "with open(PROJECT_DATA+\"/restaurants.json\", 'r') as f:\n",
        "    restaurants = json.load(f)\n",
        "#print(restaurants)\n",
        "def api_call (input_slots):\n",
        "    print('search' , input_slots)\n",
        "    res = []\n",
        "    for restaurant in restaurants:\n",
        "        #print( sear input_slots)\n",
        "        for k, v in input_slots.items():\n",
        "            if v== 'dontcare' or v==None:\n",
        "                continue\n",
        "            if k in restaurant and restaurant[k] != v :\n",
        "                break\n",
        "        else:\n",
        "            res.append(restaurant)\n",
        "    return res"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WoiCZxan_ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0aebcf2-3078-43a2-e5cd-896a49ded000"
      },
      "source": [
        "import random\n",
        "\n",
        "\n",
        "\n",
        "class BOT:\n",
        "\n",
        "    unsuported_acts={'unknown',\n",
        "                        'thankyou',\n",
        "                        #'restart',\n",
        "                        'reqmore',\n",
        "                        #'reqalts',\n",
        "                        'repeat',\n",
        "                        'negate',\n",
        "                        #'hello',\n",
        "                        'deny_name',\n",
        "                        'deny_food',\n",
        "                        'confirm_pricerange',\n",
        "                        'confirm_food',\n",
        "                        'confirm_area',\n",
        "                        #'bye',\n",
        "                        'affirm',\n",
        "                        'ack'}\n",
        "\n",
        "    state0 = {  'prev_acts':[],\n",
        "                'slots':{   'food':None,\n",
        "                            'area': None,\n",
        "                            'pricerange': None\n",
        "                        },\n",
        "                'recomanded':[],\n",
        "                'restaurant_curser':None,\n",
        "                'this':None,\n",
        "                'repvious_this':False}\n",
        "            \n",
        "    def __init__(self, nul, joint_model,tokenizer,INTENT_ITEMS, NER_ITEMS, templates):\n",
        "        self.nlu = nul\n",
        "        self.joint_model = joint_model\n",
        "        self.INTENT_ITEMS = INTENT_ITEMS\n",
        "        self.NER_ITEMS = NER_ITEMS\n",
        "        self.templates = templates\n",
        "        self.tokenizer = tokenizer\n",
        "        self.state = self.state0\n",
        "   \n",
        "        #print(self.render_template('welcomemsg'))\n",
        "\n",
        "    def render_template(self, key,slots=[]):\n",
        "        str_ = self.templates[key]\n",
        "        #print(\"will return: \",str_)\n",
        "        #for k,v in slots.items():\n",
        "        for k,v in self.state['slots'].items():\n",
        "            if v is not None:\n",
        "                str_ = str_.replace('#'+k,v)\n",
        "                #print('randering ', str_, ' ', '#'+k,' ' ,v)\n",
        "        if self.state['restaurant_curser'] is not None:        \n",
        "            print(self.state['restaurant_curser'])\n",
        "            for k,v in self.state['restaurant_curser'].items():\n",
        "                str_ = str_.replace('#'+k,v)\n",
        "                    #print('randering ', str_, ' ', '#'+k,' ' ,v)       \n",
        "        return str_  \n",
        "\n",
        "    def match_(self, tokens):\n",
        "        for k in self.templates:\n",
        "            items = k.split('+')\n",
        "            #print(items, tokens)\n",
        "            if len(tokens) == len(items) and all(x in items for x in tokens):\n",
        "                return k\n",
        "             \n",
        "\n",
        "\n",
        "    def next_act(self,intents, slots):\n",
        "        intents = [item for item in intents if item not in self.unsuported_acts]\n",
        "        if len(self.state['prev_acts']) ==0 and len(intents) == 0:\n",
        "            return 'welcomemsg'\n",
        "        #print(len(self.state['prev_acts']), len(intents))\n",
        "\n",
        "        recom_list = api_call(self.state['slots'])\n",
        "        #current = [x in recom_list not in x.name not in self.state[recomanded] ]\n",
        "        if len(self.state['recomanded'])>0:\n",
        "            # print(recom_list)\n",
        "            # print(self.state['recomanded'])\n",
        "            current = [x for x in recom_list if x['name'] not in [x1 for x1 in self.state['recomanded']] ]\n",
        "        else:\n",
        "            current = recom_list\n",
        "\n",
        "        #print(\"\\n\\n\\n\\ncurrent\",recom_list)\n",
        "        #food #area #pricerange 'courntKnwledge' == '000'\n",
        "        ck = '000'\n",
        "        if self.state['slots']['food'] != None:\n",
        "            ck = '100'\n",
        "        if self.state['slots']['area'] != None:\n",
        "            ck = ck[:1]+'10'\n",
        "        if self.state['slots']['pricerange'] != None:\n",
        "            ck = ck[:2]+'1'\n",
        "        \n",
        "        #print('ck', ck)\n",
        "        print('address request checking', intents)\n",
        "\n",
        "        requests = ['request_pricerange', 'request_postcode', 'request_phone',\n",
        "                                'request_food', 'request_area', 'request_addr']\n",
        "        if set(intents) <= set(requests):  \n",
        "            tokens = [ t.replace('request','inform') for t in intents]\n",
        "            print(tokens,self.match_(tokens+['inform_name']))\n",
        "            #if len(current)>0:\n",
        "            return self.match_(tokens+['offer_name'])\n",
        "            #else:    \n",
        "        else:\n",
        "            print('address request didnt catch', intents)\n",
        "\n",
        "        informs = [ 'inform_this', 'inform_pricerange', 'inform_name', 'inform_food', 'inform_area','reqalts']\n",
        "        if any(x in informs for x in intents):\n",
        "            print('he informes us let back sth or ask more ', ck)\n",
        "            \n",
        "            dual_fact=['110', '101', '101']\n",
        "            if ck in dual_fact:\n",
        "                if len(current)>0:\n",
        "                    print('current[0].name',current[0].keys())\n",
        "                    self.state['recomanded'].append(current[0]['name'])\n",
        "                    self.state['restaurant_curser'] = current[0]\n",
        "                    if ck == '110':\n",
        "                        return 'inform_addr+inform_food+offer_name' \n",
        "                    if ck == '101':\n",
        "                        return 'inform_food+inform_pricerange+offer_name' \n",
        "                    if ck == '011':\n",
        "                        return 'inform_area+inform_pricerange+offer_name' \n",
        "                    # if ck=='111':\n",
        "                    #     return 'inform_area+inform_food+inform_pricerange+offer_name'  \n",
        "                else:        \n",
        "                    if ck == '110':\n",
        "                        return 'canthelp_area_food' \n",
        "                    if ck == '101':\n",
        "                        return 'canthelp_food_pricerange' \n",
        "                    if ck == '011':\n",
        "                        return 'canthelp_area_pricerange' \n",
        "                    # if ck=='111':\n",
        "                    #     return 'canthelp_area_food_pricerange' \n",
        "            if ck=='111':\n",
        "                if len(current)>0:\n",
        "                    self.state['restaurant_curser'] = current[0]\n",
        "                    self.state['recomanded'].append(current[0]['name'])\n",
        "                    return 'inform_area+inform_food+inform_pricerange+offer_name'  \n",
        "                else:\n",
        "                    return 'canthelp_area_food_pricerange'\n",
        "\n",
        "            #if len(intents)==1:\n",
        "            #if intents[0] =='inform_food':\n",
        "            if 'inform_food' in intents:\n",
        "                if ck == '100':\n",
        "                    if len(current) == 0:\n",
        "                        return 'canthelp_food'\n",
        "                    else:\n",
        "                        return random.choice(['request_area','request_pricerange','impl-conf_food+request_area','impl-conf_food+request_area'])                        \n",
        "            #if len(intents)==1 and 'inform_area':\n",
        "            if 'inform_area' in intents:\n",
        "                if ck == '010':\n",
        "                    if len(current) == 0:\n",
        "                        return 'canthelp_area'\n",
        "                    else:\n",
        "                        return random.choice(['request_food','request_pricerange','impl-conf_food+request_area','impl-conf_food+request_area'])                        \n",
        "\n",
        "            #if len(intents)==1 and 'inform_pricerange':\n",
        "            if 'inform_pricerange' in intents:\n",
        "                if ck == '001':\n",
        "                    if len(current) == 0:\n",
        "                        return 'select_pricerange'\n",
        "                    else:\n",
        "                        return random.choice(['request_food','request_area'])\n",
        "        # if 'reqalts' in intents:\n",
        "        #     if len(current) == 0:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #print('we are in last lines')\n",
        "        if 'bye' in intents:\n",
        "            return 'bye'\n",
        "        \n",
        "        if len(intents)==1 and (intents[0]=='hello' or  intents[0]=='restart'):\n",
        "            self.state = self.state0\n",
        "            return 'request_food'\n",
        "\n",
        "        return  'confirm-domain'\n",
        "\n",
        "\n",
        "    def __call__(self, talklist):\n",
        "        conversation = []\n",
        "        for talk in talklist:\n",
        "            t = self.nlu(talk, tokenizer,joint_model,INTENT_ITEMS, NER_ITEMS)\n",
        "            print(\"nlu: \",talk, t)\n",
        "            for k,v in t['slots'].items():\n",
        "\n",
        "                #self.state['slots'][k]=v\n",
        "                self.state['slots'][k] = get_real_val(k,v)\n",
        "\n",
        "            if 'inform_this' in t['intent'] and 'this' in t['slots']:\n",
        "                #self.state['slots'][ self.state['this'] ] = t['slots']['this']\n",
        "                self.state['slots'][ self.state['this'] ] = get_real_val(self.state['this'],t['slots']['this'])\n",
        "\n",
        "            act_name = self.next_act(t['intent'],t['slots'])\n",
        "\n",
        "            #print('the act in call',act_name)\n",
        "            if 'request_food' == act_name:\n",
        "                self.state['this'] = 'food'\n",
        "            elif 'request_area' == act_name:\n",
        "                self.state['this'] = 'area'\n",
        "            elif 'request_pricerange' == act_name:\n",
        "                self.state['this'] = 'pricerange'\n",
        "            else:    \n",
        "                self.state['this'] = None\n",
        "\n",
        "            self.state['prev_acts'].append(act_name)\n",
        "            response = self.render_template(act_name,self.state['slots'])\n",
        "            #return self.render_template(act_name,self.state['slots'] )\n",
        "            print(self.state)\n",
        "\n",
        "            conversation.append('user: '+ talk)\n",
        "            conversation.append('bot: '+  response)\n",
        "            conversation.append('')\n",
        "\n",
        "            # print('user: ')\n",
        "            # print(talk)\n",
        "            # print(' bot: ')\n",
        "            # print(response)\n",
        "        return conversation\n",
        "\n",
        "#1-food 2-area 3-pricerange\n",
        "bot = BOT(nlu, joint_model,tokenizer,INTENT_ITEMS, NER_ITEMS, templates)\n",
        "\n",
        "# print (nlu(\"hi, i want to eat, can you suggest a place to go?\", tokenizer, joint_model, \n",
        "#     INTENT_ITEMS, NER_ITEMS))\n",
        "# bot = print(bot(['hi, i want to eat, can you suggest a place to go?']))\n",
        "\n",
        "\n",
        "t = [\n",
        "     'hi',\n",
        "    #  'i am looking for chinese food',\n",
        "    #  'what can i eat in city center',\n",
        "    #  'where can i eat some thing chaep'\n",
        "     'a cheap restaurant plz',\n",
        "     'chinese',\n",
        "     'address' ,  \n",
        "     'how about west is there any there',\n",
        "      ]\n",
        "# print (nlu(t[-1], tokenizer, joint_model, \n",
        "#     INTENT_ITEMS, NER_ITEMS))\n",
        "get_result = bot(t)\n",
        "\n",
        "for t1 in get_result:\n",
        "    print(t1)\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nlu:  hi {'intent': [], 'slots': {}}\n",
            "{'prev_acts': ['welcomemsg'], 'slots': {'food': None, 'area': None, 'pricerange': None}, 'recomanded': [], 'restaurant_curser': None, 'this': None, 'repvious_this': False}\n",
            "nlu:  a cheap restaurant plz {'intent': ['inform_pricerange'], 'slots': {'pricerange': 'cheap'}}\n",
            "search {'food': None, 'area': None, 'pricerange': 'cheap'}\n",
            "address request checking ['inform_pricerange']\n",
            "address request didnt catch ['inform_pricerange']\n",
            "he informes us let back sth or ask more  001\n",
            "{'prev_acts': ['welcomemsg', 'request_food'], 'slots': {'food': None, 'area': None, 'pricerange': 'cheap'}, 'recomanded': [], 'restaurant_curser': None, 'this': 'food', 'repvious_this': False}\n",
            "nlu:  chinese {'intent': ['inform_food'], 'slots': {'food': 'chinese'}}\n",
            "search {'food': 'chinese', 'area': None, 'pricerange': 'cheap'}\n",
            "address request checking ['inform_food']\n",
            "address request didnt catch ['inform_food']\n",
            "he informes us let back sth or ask more  101\n",
            "current[0].name dict_keys(['food', 'pricerange', 'addr', 'phone', 'postcode', 'area', 'name'])\n",
            "{'food': 'chinese', 'pricerange': 'cheap', 'addr': 'regent street city centre', 'phone': '01223 361763', 'postcode': 'c.b 2, 1 d.b', 'area': 'centre', 'name': 'charlie chan'}\n",
            "{'prev_acts': ['welcomemsg', 'request_food', 'inform_food+inform_pricerange+offer_name'], 'slots': {'food': 'chinese', 'area': None, 'pricerange': 'cheap'}, 'recomanded': ['charlie chan'], 'restaurant_curser': {'food': 'chinese', 'pricerange': 'cheap', 'addr': 'regent street city centre', 'phone': '01223 361763', 'postcode': 'c.b 2, 1 d.b', 'area': 'centre', 'name': 'charlie chan'}, 'this': None, 'repvious_this': False}\n",
            "nlu:  address {'intent': ['request_addr'], 'slots': {}}\n",
            "search {'food': 'chinese', 'area': None, 'pricerange': 'cheap'}\n",
            "address request checking ['request_addr']\n",
            "['inform_addr'] None\n",
            "{'food': 'chinese', 'pricerange': 'cheap', 'addr': 'regent street city centre', 'phone': '01223 361763', 'postcode': 'c.b 2, 1 d.b', 'area': 'centre', 'name': 'charlie chan'}\n",
            "{'prev_acts': ['welcomemsg', 'request_food', 'inform_food+inform_pricerange+offer_name', 'inform_addr+offer_name'], 'slots': {'food': 'chinese', 'area': None, 'pricerange': 'cheap'}, 'recomanded': ['charlie chan'], 'restaurant_curser': {'food': 'chinese', 'pricerange': 'cheap', 'addr': 'regent street city centre', 'phone': '01223 361763', 'postcode': 'c.b 2, 1 d.b', 'area': 'centre', 'name': 'charlie chan'}, 'this': None, 'repvious_this': False}\n",
            "nlu:  how about west is there any there {'intent': ['reqalts', 'inform_area'], 'slots': {'area': 'west'}}\n",
            "search {'food': 'chinese', 'area': 'west', 'pricerange': 'cheap'}\n",
            "address request checking ['reqalts', 'inform_area']\n",
            "address request didnt catch ['reqalts', 'inform_area']\n",
            "he informes us let back sth or ask more  111\n",
            "{'food': 'chinese', 'pricerange': 'cheap', 'addr': 'regent street city centre', 'phone': '01223 361763', 'postcode': 'c.b 2, 1 d.b', 'area': 'centre', 'name': 'charlie chan'}\n",
            "{'prev_acts': ['welcomemsg', 'request_food', 'inform_food+inform_pricerange+offer_name', 'inform_addr+offer_name', 'canthelp_area_food_pricerange'], 'slots': {'food': 'chinese', 'area': 'west', 'pricerange': 'cheap'}, 'recomanded': ['charlie chan'], 'restaurant_curser': {'food': 'chinese', 'pricerange': 'cheap', 'addr': 'regent street city centre', 'phone': '01223 361763', 'postcode': 'c.b 2, 1 d.b', 'area': 'centre', 'name': 'charlie chan'}, 'this': None, 'repvious_this': False}\n",
            "user: hi\n",
            "bot: Hello, welcome to the Cambridge restaurant system. You can ask for restaurants by area, price range or food type. How may I help you?\n",
            "\n",
            "user: a cheap restaurant plz\n",
            "bot: What kind of food would you like?\n",
            "\n",
            "user: chinese\n",
            "bot: charlie chan serves chinese food in the cheap price range.\n",
            "\n",
            "user: address\n",
            "bot: Sure, charlie chan is on regent street city centre.\n",
            "\n",
            "user: how about west is there any there\n",
            "bot: Sorry there is no cheap restaurant in the west of town serving chinese food.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}