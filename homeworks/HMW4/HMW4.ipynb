{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0AUiQtZHOqZY",
        "DIxbKRYRO42g",
        "os2hYPlnQQTV",
        "aFynGDkEWY2D",
        "DSFbNBT9D-ST",
        "R67IRlxnECO3",
        "g-m8tVdWGM2t",
        "inBjDjn-BR0d",
        "erhDpL-8BVQW",
        "xTvMbVtYKWvD",
        "QtmBCg_RKda7",
        "xZBbs7J5USqC",
        "31Wm5EDfjGoI"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1"
      ],
      "metadata": {
        "id": "0AUiQtZHOqZY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ILqqhiqKLAom"
      },
      "outputs": [],
      "source": [
        "sentences = ['انتخابات هفته آینده رادر تهران برگزار میکنیم ، اما دسته بندی حوزهها برای رأی گیری از این هفته آغاز شده است',\n",
        "             'توانتشارخبرمهم در رسانه ها را تایید کردی',\n",
        "             'پسردکتراحمدی درکارنامه حرفه ای خود ۱۸سریال تلویزیونی و ۱۲فیلم سینمایی دارد',\n",
        "             'نقّاشی ساختمان به پایان رسیدددددددد',\n",
        "             'اللة اکبر گویان وارد مسجد شد',\n",
        "             'دکتر جان مممممممممممممممنونم که مشکلات حرکتي فرزندم را درمان کردید']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer"
      ],
      "metadata": {
        "id": "DIxbKRYRO42g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Hazm"
      ],
      "metadata": {
        "id": "8L7NXJq7O9Qq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[github](https://github.com/sobhe/hazm)\n",
        "\n",
        "[document](https://www.roshan-ai.ir/hazm/docs/content/modules/)"
      ],
      "metadata": {
        "id": "CiveNsXyFUVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hazm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOjsEwRLY9CF",
        "outputId": "32fdba29-2caf-4cbb-96a8-77c7d4da4fb9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hazm\n",
            "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1\n",
            "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 50.8 MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 55.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Building wheels for collected packages: nltk, libwapiti\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394487 sha256=6e487c33888f4ac100556a191b8cb6ae9536fa6462c9b36d3668d16b0f67cfe9\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154487 sha256=2c4b750604a987abc0cca67d9aea7e88eed77d3fa758f1cc83a21ad527a8ff7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n",
            "Successfully built nltk libwapiti\n",
            "Installing collected packages: nltk, libwapiti, hazm\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hazm import word_tokenize"
      ],
      "metadata": {
        "id": "wiTL6au5HjZP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hazm_tokenized(sentences):\n",
        "  new_sents = []\n",
        "  tokenized_word = [word_tokenize(sent) for sent in sentences]\n",
        "  for sent in tokenized_word:\n",
        "    new_sents.append(' '.join(sent))\n",
        "  return new_sents, tokenized_word"
      ],
      "metadata": {
        "id": "EPxXU3MmUuiw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_hazm_sent, tokenized_word_hazm = hazm_tokenized(sentences)"
      ],
      "metadata": {
        "id": "FFhUcYsOVUP2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in tokenized_word_hazm:\n",
        "    print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMtaBf-1PjpM",
        "outputId": "5411d2fa-d0ad-4866-c936-cd9d6b0378a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['انتخابات', 'هفته', 'آینده', 'رادر', 'تهران', 'برگزار', 'میکنیم', '،', 'اما', 'دسته', 'بندی', 'حوزهها', 'برای', 'رأی', 'گیری', 'از', 'این', 'هفته', 'آغاز', 'شده_است']\n",
            "['توانتشارخبرمهم', 'در', 'رسانه', 'ها', 'را', 'تایید', 'کردی']\n",
            "['پسردکتراحمدی', 'درکارنامه', 'حرفه', 'ای', 'خود', '۱۸', 'سریال', 'تلویزیونی', 'و', '۱۲', 'فیلم', 'سینمایی', 'دارد']\n",
            "['نقّاشی', 'ساختمان', 'به', 'پایان', 'رسیدددددددد']\n",
            "['اللة', 'اکبر', 'گویان', 'وارد', 'مسجد', 'شد']\n",
            "['دکتر', 'جان', 'مممممممممممممممنونم', 'که', 'مشکلات', 'حرکتي', 'فرزندم', 'را', 'درمان', 'کردید']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Parsivar"
      ],
      "metadata": {
        "id": "os2hYPlnQQTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install parsivar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "qrXpPQsfY_s_",
        "outputId": "5737d13c-9785-4142-8da0-6acc829daa0b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting parsivar\n",
            "  Downloading parsivar-0.2.3.tar.gz (36.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 36.2 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 35.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.5->parsivar) (1.15.0)\n",
            "Building wheels for collected packages: parsivar, nltk\n",
            "  Building wheel for parsivar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsivar: filename=parsivar-0.2.3-py3-none-any.whl size=36492972 sha256=fb07abeb5b64e1e013f95afd891e98aee5f5aefa04640e54098527508871d651\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/67/7a/49cbf08f64d3f76a26eceaf0e481a40e233f05d4356875cbed\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449922 sha256=fc8d673d4a65e3e759737361dc370029bfe80b66a1ee670a1b401f6747a63219\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "Successfully built parsivar nltk\n",
            "Installing collected packages: nltk, parsivar\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.3\n",
            "    Uninstalling nltk-3.3:\n",
            "      Successfully uninstalled nltk-3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "hazm 0.7.0 requires nltk==3.3, but you have nltk 3.4.5 which is incompatible.\u001b[0m\n",
            "Successfully installed nltk-3.4.5 parsivar-0.2.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nltk"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from parsivar import Tokenizer"
      ],
      "metadata": {
        "id": "n9ty_TmFQSC0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_parsivar = Tokenizer()\n",
        "tokenized_word_parsivar = [tokenizer_parsivar.tokenize_words(sent) for sent in sentences]"
      ],
      "metadata": {
        "id": "7MWqI5Z4QX8C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parsivar_tokenizer(sentences):\n",
        "  tokenizer_parsivar = Tokenizer()\n",
        "  tokenized_word = [tokenizer_parsivar.tokenize_words(sent) for sent in sentences]\n",
        "  new_sent = []\n",
        "  for words in tokenized_word:\n",
        "    new_sent.append(' '.join(words))\n",
        "  return new_sent, tokenized_word"
      ],
      "metadata": {
        "id": "VTdYeicdVxgq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_parsivar_sent, tokenized_word_parsivar = parsivar_tokenizer(sentences)"
      ],
      "metadata": {
        "id": "jjxx0vh_WsEE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in tokenized_word_parsivar:\n",
        "    print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkL1giNCRE1y",
        "outputId": "7fc1047c-9596-48df-b5e4-d2b12fa83cc9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['انتخابات', 'هفته', 'آینده', 'رادر', 'تهران', 'برگزار', 'میکنیم', '،', 'اما', 'دسته', 'بندی', 'حوزهها', 'برای', 'رأی', 'گیری', 'از', 'این', 'هفته', 'آغاز', 'شده', 'است']\n",
            "['توانتشارخبرمهم', 'در', 'رسانه', 'ها', 'را', 'تایید', 'کردی']\n",
            "['پسردکتراحمدی', 'درکارنامه', 'حرفه', 'ای', 'خود', '۱۸سریال', 'تلویزیونی', 'و', '۱۲فیلم', 'سینمایی', 'دارد']\n",
            "['نقّاشی', 'ساختمان', 'به', 'پایان', 'رسیدددددددد']\n",
            "['اللة', 'اکبر', 'گویان', 'وارد', 'مسجد', 'شد']\n",
            "['دکتر', 'جان', 'مممممممممممممممنونم', 'که', 'مشکلات', 'حرکتي', 'فرزندم', 'را', 'درمان', 'کردید']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Polyglot"
      ],
      "metadata": {
        "id": "aFynGDkEWY2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install polyglot\n",
        "!pip install PyICU\n",
        "!pip install pycld2\n",
        "!pip install morfessor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm35jRdqZCvB",
        "outputId": "7151d56e-6284-4c51-bf18-237b76dc652c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting polyglot\n",
            "  Downloading polyglot-16.7.4.tar.gz (126 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 19.7 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 126 kB 5.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: polyglot\n",
            "  Building wheel for polyglot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for polyglot: filename=polyglot-16.7.4-py2.py3-none-any.whl size=52577 sha256=401a1b2071f47b1365ccf59f4dba89e92df22683fd7b815ec943b74138bee115\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/bc/67/75c9de8e9726460bc0b101ad225ad025cb8ce9e0759beb9d52\n",
            "Successfully built polyglot\n",
            "Installing collected packages: polyglot\n",
            "Successfully installed polyglot-16.7.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyICU\n",
            "  Downloading PyICU-2.9.tar.gz (305 kB)\n",
            "\u001b[K     |████████████████████████████████| 305 kB 5.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: PyICU\n",
            "  Building wheel for PyICU (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyICU: filename=PyICU-2.9-cp37-cp37m-linux_x86_64.whl size=1375743 sha256=5ecfbf8509618ef025bdb09d0704e8600ffa03926abb3d6b4ac7d3fb40a4373e\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/88/93/6c1b06361e4cbd4e7f793fb456729f69798f9aa3fc2a791cd7\n",
            "Successfully built PyICU\n",
            "Installing collected packages: PyICU\n",
            "Successfully installed PyICU-2.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycld2\n",
            "  Downloading pycld2-0.41.tar.gz (41.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 41.4 MB 1.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pycld2\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp37-cp37m-linux_x86_64.whl size=9834301 sha256=d22063e90ca8f0f140e967d55145b9fa15babdc716a32cb678ba890230a3e8da\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/e4/58/ed2e9f43c07d617cc81fe7aff0fc6e42b16c9cf6afe960b614\n",
            "Successfully built pycld2\n",
            "Installing collected packages: pycld2\n",
            "Successfully installed pycld2-0.41\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: morfessor\n",
            "Successfully installed morfessor-2.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from polyglot.text import Text"
      ],
      "metadata": {
        "id": "v2ckcT9bW6RW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_words_polyglot = [Text(sent).words for sent in sentences]"
      ],
      "metadata": {
        "id": "Nl9mfmsrWpbr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in tokenized_words_polyglot:\n",
        "    print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZHAITCqAsl4",
        "outputId": "087dd7f9-be54-48af-deeb-de466cc7a2cb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['انتخابات', 'هفته', 'آینده', 'رادر', 'تهران', 'برگزار', 'میکنیم', '،', 'اما', 'دسته', 'بندی', 'حوزهها', 'برای', 'رأی', 'گیری', 'از', 'این', 'هفته', 'آغاز', 'شده', 'است']\n",
            "['توانتشارخبرمهم', 'در', 'رسانه', 'ها', 'را', 'تایید', 'کردی']\n",
            "['پسردکتراحمدی', 'درکارنامه', 'حرفه', 'ای', 'خود', '۱۸سریال', 'تلویزیونی', 'و', '۱۲فیلم', 'سینمایی', 'دارد']\n",
            "['نقّاشی', 'ساختمان', 'به', 'پایان', 'رسیدددددددد']\n",
            "['اللة', 'اکبر', 'گویان', 'وارد', 'مسجد', 'شد']\n",
            "['دکتر', 'جان', 'مممممممممممممممنونم', 'که', 'مشکلات', 'حرکتي', 'فرزندم', 'را', 'درمان', 'کردید']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalizer"
      ],
      "metadata": {
        "id": "d1kZY6sKBInW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Hazm"
      ],
      "metadata": {
        "id": "a0Sl2OdIBNJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Simple"
      ],
      "metadata": {
        "id": "DSFbNBT9D-ST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hazm import Normalizer"
      ],
      "metadata": {
        "id": "mSs_H_IvC9pj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hazm_simple_normalizer = Normalizer()"
      ],
      "metadata": {
        "id": "Lop_AuRvCEGF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_normalized_hazm = [hazm_simple_normalizer.normalize(sent) for sent in sentences]"
      ],
      "metadata": {
        "id": "sC1iOHcQCIL4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in simple_normalized_hazm:\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3RY1WZ1CQMx",
        "outputId": "a0d0c7da-2e31-4007-d8bb-6233b1fe650c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "انتخابات هفته آینده رادر تهران برگزار میکنیم، اما دسته بندی حوزهها برای رأی گیری از این هفته آغاز شده است\n",
            "توانتشارخبرمهم در رسانه‌ها را تایید کردی\n",
            "پسردکتراحمدی درکارنامه حرفه‌ای خود ۱۸سریال تلویزیونی و ۱۲فیلم سینمایی دارد\n",
            "نقاشی ساختمان به پایان رسیدددددددد\n",
            "اللة اکبر گویان وارد مسجد شد\n",
            "دکتر جان مممممممممممممممنونم که مشکلات حرکتی فرزندم را درمان کردید\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. Informal"
      ],
      "metadata": {
        "id": "R67IRlxnECO3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizing informal texts"
      ],
      "metadata": {
        "id": "8yQ7l1B-F6R7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hazm import InformalNormalizer"
      ],
      "metadata": {
        "id": "34JCbxoUEHQ3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "informal_hazm_normalizer = InformalNormalizer()"
      ],
      "metadata": {
        "id": "r2Hj1y_dEKVZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inf_normalized_hazm = [informal_hazm_normalizer.normalize(sent) for sent in sentences]"
      ],
      "metadata": {
        "id": "4RG7xqOwEOy7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in inf_normalized_hazm:\n",
        "  print(sent)\n",
        "  print('----')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swm4On-jEYXB",
        "outputId": "74f4c2cf-1a9f-48a5-dbb4-120959bb14c8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[['انتخابات'], ['هفته'], ['آینده'], ['رادر'], ['تهران'], ['برگزار'], ['می\\u200cکنیم', 'میکنیم'], ['،'], ['اما'], ['دسته'], ['بندی'], ['حوزهها'], ['برای'], ['رأی'], ['گیری'], ['از'], ['این'], ['هفته'], ['آغاز'], ['شده_است']]]\n",
            "----\n",
            "[[['توانتشارخبرمهم'], ['در'], ['رسانه\\u200cها'], ['را'], ['تایید'], ['کردی']]]\n",
            "----\n",
            "[[['پسردکتراحمدی'], ['درکارنامه'], ['حرفه\\u200cای'], ['خود'], ['۱۸'], ['سریال'], ['تلویزیونی'], ['و'], ['۱۲'], ['فیلم'], ['سینمایی'], ['دارد']]]\n",
            "----\n",
            "[[['نقاشی'], ['ساختمان'], ['به'], ['پایان'], ['رسیدددددددد']]]\n",
            "----\n",
            "[[['اللة'], ['اکبر'], ['گویان'], ['وارد'], ['مسجد'], ['شد']]]\n",
            "----\n",
            "[[['دکتر'], ['جان'], ['مممممممممممممممنونم'], ['که'], ['مشکلات'], ['حرکتی'], ['فرزندم'], ['را'], ['درمان'], ['کردید']]]\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Mix"
      ],
      "metadata": {
        "id": "g-m8tVdWGM2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hazm import Normalizer\n",
        "from hazm import InformalNormalizer"
      ],
      "metadata": {
        "id": "eT5E99tkYE_a"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hazm_normalizer(sentences):\n",
        "  new_sent = []\n",
        "  informal_hazm_normalizer = InformalNormalizer()\n",
        "  hazm_normalizer = Normalizer(remove_diacritics=True,affix_spacing=True,persian_style=True,persian_numbers=True,token_based=True)\n",
        "  for sent in sentences:\n",
        "      words = informal_hazm_normalizer.normalize(sent)\n",
        "      words = [word[0] for word in words[0]]\n",
        "      sent = ' '.join(words)\n",
        "      normalized = hazm_normalizer.normalize(sent)\n",
        "      new_sent.append(normalized)\n",
        "  return new_sent"
      ],
      "metadata": {
        "id": "rj-FS1whXV0H"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_hazm_sent = hazm_normalizer(sentences)"
      ],
      "metadata": {
        "id": "AylGSv81Xu04"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in sentences:\n",
        "  print(sent)\n",
        "  print('-----')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUbDHdivXzSo",
        "outputId": "39bda5cd-2b45-40e6-a03a-de513b0703b8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "انتخابات هفته آینده رادر تهران برگزار میکنیم ، اما دسته بندی حوزهها برای رأی گیری از این هفته آغاز شده است\n",
            "-----\n",
            "توانتشارخبرمهم در رسانه ها را تایید کردی\n",
            "-----\n",
            "پسردکتراحمدی درکارنامه حرفه ای خود ۱۸سریال تلویزیونی و ۱۲فیلم سینمایی دارد\n",
            "-----\n",
            "نقّاشی ساختمان به پایان رسیدددددددد\n",
            "-----\n",
            "اللة اکبر گویان وارد مسجد شد\n",
            "-----\n",
            "دکتر جان مممممممممممممممنونم که مشکلات حرکتي فرزندم را درمان کردید\n",
            "-----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Parsivar"
      ],
      "metadata": {
        "id": "inBjDjn-BR0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from parsivar import Normalizer"
      ],
      "metadata": {
        "id": "UJR1VjR3EGhJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_parsivar(sentences):\n",
        "  parsivar_normalizer = Normalizer()\n",
        "  normalized_parsivar = [parsivar_normalizer.normalize(sent) for sent in sentences]\n",
        "  return normalized_parsivar"
      ],
      "metadata": {
        "id": "U2bLSDsyYQF1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_parisvar_sent = normalize_parsivar(sentences)"
      ],
      "metadata": {
        "id": "jJhRire5Ya46"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in norm_parisvar_sent:\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tkt5TDPkIccl",
        "outputId": "cd7905d4-4586-4757-8c1c-23eefdc96f9a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "انتخابات هفته آینده رادر تهران برگزار می‌کنیم ، اما دسته‌بندی حوزهها برای رای‌گیری از این هفته آغاز‌شده‌است\n",
            "توانتشارخبرمهم در رسانه‌ها را تایید کردی\n",
            "پسردکتراحمدی درکارنامه حرفه‌ای خود 18سریال تلویزیونی و 12فیلم سینمایی دارد\n",
            "نقّاشی ساختمان به پایان رسیدددددددد\n",
            "الله اکبر گویان وارد مسجد شد\n",
            "دکتر جان مممممممممممممممنونم که مشکلات حرکتی فرزندم را درمان کردید\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Persianutils"
      ],
      "metadata": {
        "id": "erhDpL-8BVQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install persianutils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdTpWOSUZbuT",
        "outputId": "1e221aa6-20c0-448a-dbcc-acc40ff112c3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting persianutils\n",
            "  Downloading persianutils-0.1.2-py3-none-any.whl (9.0 kB)\n",
            "Installing collected packages: persianutils\n",
            "Successfully installed persianutils-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import persianutils as pu"
      ],
      "metadata": {
        "id": "R2FgzaXlI2Sh"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pu_normalized = [pu.standardize(sent) for sent in sentences]"
      ],
      "metadata": {
        "id": "xqwlua8eI41f"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in pu_normalized:\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOKTYYhpJNqe",
        "outputId": "0b96655b-275f-476a-dcf1-36b471ba1596"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "انتخابات هفته اینده رادر تهران برگزار میکنیم ، اما دسته بندی حوزهها برای رای گیری از این هفته اغاز شده است\n",
            "توانتشارخبرمهم در رسانه ها را تایید کردی\n",
            "پسردکتراحمدی درکارنامه حرفه ای خود ۱۸سریال تلویزیونی و ۱۲فیلم سینمایی دارد\n",
            "نقاشی ساختمان به پایان رسیدددددددد\n",
            "الله اکبر گویان وارد مسجد شد\n",
            "دکتر جان مممممممممممممممنونم که مشکلات حرکتی فرزندم را درمان کردید\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2"
      ],
      "metadata": {
        "id": "xTvMbVtYKWvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Hazm"
      ],
      "metadata": {
        "id": "QtmBCg_RKda7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Stemming"
      ],
      "metadata": {
        "id": "Cxuijd2RLDPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hazm import Stemmer"
      ],
      "metadata": {
        "id": "HqgZRclcLWyq"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hazm_stemmer(sentences):\n",
        "  new_sent= []\n",
        "  for sent in sentences:\n",
        "    words = sent.split(' ')\n",
        "    stem_words = [Stemmer().stem(word) for word in words]\n",
        "    new_sent.append(' '.join(stem_words))\n",
        "  return new_sent"
      ],
      "metadata": {
        "id": "yvQ_4_WWY-zV"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stem_hazm_sent = hazm_stemmer(sentences)"
      ],
      "metadata": {
        "id": "cwm2q0WVZPN2"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in stem_hazm_sent:\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TcsjbW6ZaIq",
        "outputId": "621b0604-ffa2-4040-bc72-b859f5f4e40d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "انتخاب هفته آینده رادر تهر برگزار میکن ، اما دسته بند حوزه برا رأ گیر از این هفته آغاز شده اس\n",
            "توانتشارخبرمه در رسانه  را تایید کرد\n",
            "پسردکتراحمد درکارنامه حرفه ا خود ۱۸سریال تلویزیون و ۱۲فیل سینما دارد\n",
            "نقّاش ساخ به پا رسیدددددددد\n",
            "اللة اکبر گو وارد مسجد شد\n",
            "دک ج مممممممممممممممنون که مشکل حرکتي فرزند را در کردید\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. Lemmatization"
      ],
      "metadata": {
        "id": "QAmWYBqjMJty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hazm import Lemmatizer"
      ],
      "metadata": {
        "id": "33KBfjeeMOFs"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hazm_lemmatization(sentences):\n",
        "  new_sent = []\n",
        "  for sent in sentences:\n",
        "    words = sent.split(' ')\n",
        "    lem_words = [Lemmatizer().lemmatize(word) for word in words]\n",
        "    new_sent.append(' '.join(lem_words))\n",
        "  return new_sent\n"
      ],
      "metadata": {
        "id": "c84EBk4VZfS-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lem_hazm_sent = hazm_lemmatization(sentences)"
      ],
      "metadata": {
        "id": "ZF-ep4hzZ3Sj"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in lem_hazm_sent:\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl262x_aZssL",
        "outputId": "77007c9f-ffa9-497d-e5a3-54e1e8071781"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "انتخابات هفته آینده رادر تهران برگزار میکنیم ، اما دسته بست#بند حوزه برای رأی گرفت#گیر از این هفته آغاز شده #است\n",
            "توانتشارخبرمهم در رسانه ها را تایید کردی\n",
            "پسردکتراحمدی درکارنامه حرفه ای خود ۱۸سریال تلویزیون و ۱۲فیلم سینمایی داشت#دار\n",
            "نقّاش ساختمان به پایان رسیدددددددد\n",
            "اللة اکبر گویان وارد مسجد شد#شو\n",
            "دکتر جان مممممممممممممممنونم که مشکلات حرکتي فرزند را درمان کرد#کن\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Stopword removal"
      ],
      "metadata": {
        "id": "SaZlrQIlNOQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sobhe/hazm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71y_VoytN-fn",
        "outputId": "941fe934-06be-4874-f853-7d690abc4f9b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hazm'...\n",
            "remote: Enumerating objects: 3172, done.\u001b[K\n",
            "remote: Counting objects: 100% (1156/1156), done.\u001b[K\n",
            "remote: Compressing objects: 100% (309/309), done.\u001b[K\n",
            "remote: Total 3172 (delta 727), reused 1027 (delta 664), pack-reused 2016\u001b[K\n",
            "Receiving objects: 100% (3172/3172), 20.96 MiB | 28.80 MiB/s, done.\n",
            "Resolving deltas: 100% (1876/1876), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hazm import stopwords_list\n",
        "stopwords = stopwords_list(\"/content/hazm/hazm/data/stopwords.dat\")"
      ],
      "metadata": {
        "id": "Y0PZvUteOHp2"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hazm_stopwords(sentences):\n",
        "  new_sent = []\n",
        "  for sent in sentences:\n",
        "    conc_words = []\n",
        "    words = sent.split(' ')\n",
        "    for word in words:\n",
        "      if word not in stopwords:\n",
        "        conc_words.append(word)\n",
        "    new_sent.append(' '.join(conc_words))\n",
        "  return new_sent"
      ],
      "metadata": {
        "id": "M4ftBgaUaFm7"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sw_hazm_sent = hazm_stopwords(sentences)"
      ],
      "metadata": {
        "id": "1pNveUSmaQZ0"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in sw_hazm_sent:\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "587LgsGUaXoD",
        "outputId": "ae0fc960-b497-4173-90af-479d13d58b3a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "انتخابات هفته آینده رادر تهران برگزار میکنیم ، حوزهها رأی هفته آغاز\n",
            "توانتشارخبرمهم رسانه ها تایید کردی\n",
            "پسردکتراحمدی درکارنامه حرفه ای ۱۸سریال تلویزیونی ۱۲فیلم سینمایی\n",
            "نقّاشی ساختمان پایان رسیدددددددد\n",
            "اللة اکبر گویان مسجد\n",
            "دکتر جان مممممممممممممممنونم مشکلات حرکتي فرزندم درمان کردید\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Parsivar"
      ],
      "metadata": {
        "id": "dW98N6JRKfs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Stemming"
      ],
      "metadata": {
        "id": "DJxc6QdsRWfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from parsivar import FindStems"
      ],
      "metadata": {
        "id": "u6V39_UeRVnn"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parsivar_stemming(sentences):\n",
        "  new_sent = []\n",
        "  for sent in sentences:\n",
        "    new_sent_1 = []\n",
        "    words = sent.split(' ')\n",
        "    new_sent_1 = [FindStems().convert_to_stem(word) for word in words]\n",
        "    new_sent.append(' '. join(new_sent_1))\n",
        "  return new_sent\n"
      ],
      "metadata": {
        "id": "MSVSOYAxbiVP"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stem_parsivar_sent = parsivar_stemming(sentences)"
      ],
      "metadata": {
        "id": "BWymeHb5byS4"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in stem_parsivar_sent:\n",
        "  print(sent)\n",
        "  print('------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMk1zl8rb5rv",
        "outputId": "e21bbb06-6f87-4c34-a335-1907c6d79d10"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "انتخابات هفته آینده رادر تهران برگزار کرد&کن ، اما دسته بند حوزه برای رأی گرفت&گیر از این هفته آغاز شده اس\n",
            "------\n",
            "توانتشارخبرمهم در رسانه ها را تایید کردی\n",
            "------\n",
            "پسردکتراحمدی درکارنامه حرفه ای خود ۱۸سریال تلویزیونی و ۱۲فیلم سینمایی داشت&دارد\n",
            "------\n",
            "نقّاشی ساختمان به پایان رسیدددددددد\n",
            "------\n",
            "اللة اکبر گوی وارد مسجد شد\n",
            "------\n",
            "دکتر جان مممممممممممممممنونم که مشکلات حرکتي فرزند را درمان کرد&کن\n",
            "------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. Lemmatization\n",
        "\n",
        "NOT EXIST"
      ],
      "metadata": {
        "id": "BL6yY4iSRdHn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Stopword removal\n",
        "\n",
        "NOT EXIST"
      ],
      "metadata": {
        "id": "PrkG4MkERpLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3"
      ],
      "metadata": {
        "id": "xZBbs7J5USqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Hazm"
      ],
      "metadata": {
        "id": "l2M-nZzUc76d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hazm import Normalizer"
      ],
      "metadata": {
        "id": "aj6Tv-zoZrJA"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_hazm_sent, tokenized_word_hazm = hazm_tokenized(sentences)\n",
        "norm_hazm_sent = hazm_normalizer(token_hazm_sent)"
      ],
      "metadata": {
        "id": "5zp8RSzKc7QG"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stem_hazm_sent = hazm_stemmer(norm_hazm_sent)"
      ],
      "metadata": {
        "id": "tFfE3E-9dbZT"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in stem_hazm_sent:\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtfWsQ8CdfyO",
        "outputId": "fb763cb2-5ffc-479f-95d6-51b45d048be0"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "انتخاب هفته آینده رادر تهر برگزار می‌کنیم، اما دسته‌بند حوزه برا رأی‌گیر از این هفته آغاز شده_اس\n",
            "توانتشارخبرمه در رسانه را تایید کرد\n",
            "پسردکتراحمد درکارنامه حرفه خود ۱۸ سریال تلویزیون و ۱۲ فیل سینما دارد\n",
            "نقاش ساخ به پا رسیدددددددد\n",
            "اللة اکبر گو وارد مسجد شد\n",
            "دک ج مممممممممممممممنون که مشکل حرکت فرزند را در کردید\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lem_hazm_sent = hazm_lemmatization(norm_hazm_sent)"
      ],
      "metadata": {
        "id": "hs9Uf49pdheM"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in lem_hazm_sent:\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5gEX5XadoSm",
        "outputId": "54940296-0965-4301-90f2-a5330acaa41a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "انتخابات هفته آینده رادر تهران برگزار می‌کنیم، اما دسته‌بندی حوزه برای رأی‌گیری از این هفته آغاز شد#شو\n",
            "توانتشارخبرمهم در رسانه را تایید کردی\n",
            "پسردکتراحمدی درکارنامه حرفه‌ای خود ۱۸ سریال تلویزیون و ۱۲ فیلم سینمایی داشت#دار\n",
            "نقاش ساختمان به پایان رسیدددددددد\n",
            "اللة اکبر گویان وارد مسجد شد#شو\n",
            "دکتر جان مممممممممممممممنونم که مشکلات حرکت فرزند را درمان کرد#کن\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sw_hazm_sent = hazm_stopwords(norm_hazm_sent)"
      ],
      "metadata": {
        "id": "GVjvyvxbdoq_"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in sw_hazm_sent:\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxA1GzxDduCC",
        "outputId": "33a6030c-0f3f-4df2-9bf8-0e2514fc3fc3"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "انتخابات هفته آینده رادر تهران برگزار می‌کنیم، دسته‌بندی حوزهها رأی‌گیری هفته آغاز\n",
            "توانتشارخبرمهم رسانه‌ها تایید کردی\n",
            "پسردکتراحمدی درکارنامه حرفه‌ای ۱۸ سریال تلویزیونی ۱۲ فیلم سینمایی\n",
            "نقاشی ساختمان پایان رسیدددددددد\n",
            "اللة اکبر گویان مسجد\n",
            "دکتر جان مممممممممممممممنونم مشکلات حرکتی فرزندم درمان کردید\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Parsivar"
      ],
      "metadata": {
        "id": "GC7GTA4RiZPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_parsivar_sent, tokenized_word_parsivar = parsivar_tokenizer(sentences)\n",
        "norm_parisvar_sent = normalize_parsivar(token_parsivar_sent)"
      ],
      "metadata": {
        "id": "guqulPP5ikWZ"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stem_parsivar_sent = parsivar_stemming(norm_parisvar_sent)"
      ],
      "metadata": {
        "id": "a3__Fk0tix9V"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in stem_parsivar_sent:\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JEYycyni2H7",
        "outputId": "3884685e-5027-4c1e-c4dc-39498f2aef0a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "انتخابات هفته آینده رادر تهران برگزار میکنیم، اما دسته بند حوزه برای رأی گرفت&گیر از این هفته آغاز شده اس\n",
            "توانتشارخبرمهم در رسانه را تایید کردی\n",
            "پسردکتراحمدی درکارنامه حرفه‌ای خود ۱۸سریال تلویزیونی و ۱۲فیلم سینمایی داشت&دارد\n",
            "نقاشی ساختمان به پایان رسیدددددددد\n",
            "اللة اکبر گوی وارد مسجد شد\n",
            "دکتر جان مممممممممممممممنونم که مشکلات حرکتی فرزند را درمان کرد&کن\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4"
      ],
      "metadata": {
        "id": "31Wm5EDfjGoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "since hazm has more functions its better"
      ],
      "metadata": {
        "id": "T1GyLNpDjiUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 5"
      ],
      "metadata": {
        "id": "lAryevpljlsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1rovazK48q7pHcEM271aX70Dr594NYQ77\n",
        "!gdown 1ZCHuj6JtyOkb5ismn3qF3Rp2DRGJ1tRk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw0CbA4Zjnap",
        "outputId": "02be1183-ed2e-4554-8d57-6ca250664067"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rovazK48q7pHcEM271aX70Dr594NYQ77\n",
            "To: /content/train.csv\n",
            "100% 20.1M/20.1M [00:00<00:00, 108MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZCHuj6JtyOkb5ismn3qF3Rp2DRGJ1tRk\n",
            "To: /content/test.csv\n",
            "100% 2.03M/2.03M [00:00<00:00, 177MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from functools import lru_cache"
      ],
      "metadata": {
        "id": "Gy8h2z2FrTYr"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "false_words = ['اختصاد','سادرات','فوتکال', 'مسابغاط', 'وازدات', 'مشرکت','کشوور','منجلسه']"
      ],
      "metadata": {
        "id": "FRvXbyVrs2Cd"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('test.csv')\n",
        "train_data = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "KQH67TdPp-Eu"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = pd.concat([test_data,train_data])"
      ],
      "metadata": {
        "id": "FKSiZdT0r69r"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dictionary(input_dic):\n",
        "  count_dic = {}\n",
        "  for index,row in input_dic.iterrows():\n",
        "    words = row.article.split(' ')\n",
        "    for word in words:\n",
        "      if word not in count_dic.keys():\n",
        "        count_dic[word] = 1\n",
        "      else:\n",
        "        count_dic[word] +=1\n",
        "  return count_dic"
      ],
      "metadata": {
        "id": "3YiTQ5fBsD22"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dic = {k:v for k,v in create_dictionary(all_data).items() if v > 3}"
      ],
      "metadata": {
        "id": "R8Qmk9F2sp6W"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lev_dist(a, b):\n",
        "    @lru_cache(None)  # for memorization\n",
        "    def min_dist(s1, s2):\n",
        "        if s1 == len(a) or s2 == len(b):\n",
        "            return len(a) - s1 + len(b) - s2\n",
        "        # no change required\n",
        "        if a[s1] == b[s2]:\n",
        "            return min_dist(s1 + 1, s2 + 1)\n",
        "        return 1 + min(\n",
        "            min_dist(s1, s2 + 1),      # insert character\n",
        "            min_dist(s1 + 1, s2),      # delete character\n",
        "            min_dist(s1 + 1, s2 + 1),  # replace character\n",
        "        )\n",
        "    return min_dist(0, 0)"
      ],
      "metadata": {
        "id": "Lm1lPczCvsoB"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lev_distances = {}\n",
        "for word in false_words:\n",
        "  for k,v in base_dic.items():\n",
        "    if word not in lev_distances.keys():\n",
        "       lev_distances[word] = []\n",
        "    else:\n",
        "      lev_distances[word].append((k,lev_dist(k,word)))"
      ],
      "metadata": {
        "id": "feaF1cRHxP0o"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k,v in lev_distances.items():\n",
        "  lev_distances[k]= sorted(lev_distances[k], key=lambda x:x[1])"
      ],
      "metadata": {
        "id": "3ltsdlMz0NWU"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in false_words:\n",
        "  print(word)\n",
        "  print(lev_distances[word][:5])\n",
        "  print('------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlcOmb7_0A0k",
        "outputId": "e9366b33-7dd2-4cb4-e133-88129ab786a7"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "اختصاد\n",
            "[('اختصار', 1), ('اختصاص', 1), ('اقتصاد', 1), ('افتاد', 2), ('اتحاد', 2)]\n",
            "------\n",
            "سادرات\n",
            "[('صادرات', 1), ('سادات', 1), ('صادراتي', 2), ('خسارات', 2), ('خاطرات', 2)]\n",
            "------\n",
            "فوتکال\n",
            "[('فوتبال', 1), ('فوتسال', 1), ('فوتبال،', 2), ('فوتبالي', 2), ('نوترال', 2)]\n",
            "------\n",
            "مسابغاط\n",
            "[('مسابقات', 2), ('مساولان', 3), ('مساال', 3), ('مسابقهٌ', 3), ('مسابقه', 3)]\n",
            "------\n",
            "وازدات\n",
            "[('واردات', 1), ('وادار', 2), ('بازداشت', 2), ('وامدار', 2), ('عادات', 2)]\n",
            "------\n",
            "مشرکت\n",
            "[('مشاركت', 2), ('شركت', 2), ('مشروع', 2), ('مشرف،', 2), ('مشرف', 2)]\n",
            "------\n",
            "کشوور\n",
            "[('كشور', 2), ('مشهور', 2), ('شور', 2), ('دشوار', 2), ('شوهر', 2)]\n",
            "------\n",
            "منجلسه\n",
            "[('جلسه', 2), ('مجلس', 2), ('مجلس،', 2), ('منزله', 2), ('آنجلس', 2)]\n",
            "------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 6"
      ],
      "metadata": {
        "id": "bG_z6zY13LHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ngrams\n",
        "from nltk import FreqDist"
      ],
      "metadata": {
        "id": "3DoRzExh8wsf"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_docs = []\n",
        "for index,row in train_data.iterrows():\n",
        "  all_docs.append(row.article)"
      ],
      "metadata": {
        "id": "8eWWn64a85xO"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_unigram(all_docs):\n",
        "  all_word = 0\n",
        "  base_dic = {}\n",
        "  for doc in all_docs:\n",
        "    words = doc.split(' ')\n",
        "    for word in words:\n",
        "      if word not in base_dic.keys():\n",
        "        base_dic[word] = 1\n",
        "      else:\n",
        "        base_dic[word] +=1\n",
        "      all_word +=1\n",
        "  return base_dic,all_word"
      ],
      "metadata": {
        "id": "aaNueIuq9SuD"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_dic, total_word = create_unigram(all_docs)"
      ],
      "metadata": {
        "id": "oZlqSi8e-IPh"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bigram(all_docs):\n",
        "  freq_dist = FreqDist()\n",
        "  for doc in all_docs:\n",
        "    bgs = ngrams(doc.split(' '), 2)\n",
        "    freq_dist.update(bgs)\n",
        "  return freq_dist"
      ],
      "metadata": {
        "id": "6d2yU7Tj-fKs"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_dic = create_bigram(all_docs)"
      ],
      "metadata": {
        "id": "nJOuhsqj_k-m"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bigram_prob(sentence):\n",
        "  bgs = ngrams(sentence.split(' '), 2)\n",
        "  prob = unigram_dic[sentence.split(' ')[0]]/ total_word\n",
        "  for b in bgs:\n",
        "    prob *= bigram_dic[b] / unigram_dic[b[0]]\n",
        "  return prob"
      ],
      "metadata": {
        "id": "BoFXCrzDAL-Y"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lev_bigram(wrong_word,phrase):\n",
        "  most_relative = lev_distances[wrong_word][:5]\n",
        "  probability = {}\n",
        "  for word in most_relative:\n",
        "    temp = phrase.replace(wrong_word,word[0])\n",
        "    probability[word] = bigram_prob(temp)\n",
        "  return sorted(probability.items(),key= lambda x: x[1],reverse = True)\n"
      ],
      "metadata": {
        "id": "YJ6uAf_HG2H3"
      },
      "execution_count": 161,
      "outputs": []
    }
  ]
}