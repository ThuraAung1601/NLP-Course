{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjq6MC8BIsSk"
      },
      "source": [
        "# HW2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj1KBOTlI-Rp",
        "outputId": "7c2f5ba0-3323-4f37-f56b-ffcbba35e03c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qCVYpb67RuzUbyrJ3w-ohtCf-tzZKTal\n",
            "To: /content/train.txt\n",
            "100% 9.87M/9.87M [00:00<00:00, 295MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dW5SkCYIFbXmNe3xKv4EhrLPDPlXyIDy\n",
            "To: /content/test.txt\n",
            "100% 5.80k/5.80k [00:00<00:00, 9.72MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1qCVYpb67RuzUbyrJ3w-ohtCf-tzZKTal\n",
        "!gdown 1dW5SkCYIFbXmNe3xKv4EhrLPDPlXyIDy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTcGc_oZ42zN",
        "outputId": "b71d1110-f15b-4f9e-d609-ca8f596366be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T67ohI8LyYB"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nJVv0xJ7hrv"
      },
      "source": [
        "Bayesian smoothing with dirichlet prior : \n",
        "\n",
        "p ( wi | wi-1 ) = ( C ( wi | wi-1 ) + (mu * Pbg) ) / C( wi-1) + mu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU-qJNLiETp8"
      },
      "source": [
        "#### 1. Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0q9HZLbKIlzZ"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S3w76oVEVvv"
      },
      "source": [
        "#### 2. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2dSY73Z1JP56"
      },
      "outputs": [],
      "source": [
        "def preprocessing(file_name):\n",
        "  sentences = []\n",
        "  with open(file_name) as file:\n",
        "    for line in file:\n",
        "      line = re.sub(r\"[\\s]{2,}\",' ',line)\n",
        "      line = line.strip()\n",
        "      words = line.split(' ')\n",
        "      if len(words) > 2 :\n",
        "        sentences.append(words)\n",
        "  return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HDnHAJC6I9Ee"
      },
      "outputs": [],
      "source": [
        "train_sentences = preprocessing('train.txt')\n",
        "test_sentences = preprocessing('test.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9UiW8R3LVtM",
        "outputId": "620348dc-758f-46d7-ee3e-49dc5d581ade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "188876\n",
            "108\n"
          ]
        }
      ],
      "source": [
        "print(len(train_sentences))\n",
        "print(len(test_sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Dfr1OBibNzr6"
      },
      "outputs": [],
      "source": [
        "def word_count(sentences):\n",
        "  word_count = 0\n",
        "  word_dic = {}\n",
        "  for sentence in sentences:\n",
        "    for word in sentence:\n",
        "      if word not in word_dic.keys():\n",
        "        word_dic[word] = 1\n",
        "      else:\n",
        "        word_dic[word] += 1\n",
        "      word_count+=1\n",
        "  return word_dic, word_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AyXo75GJOVev"
      },
      "outputs": [],
      "source": [
        "train_dic, train_count = word_count(train_sentences)\n",
        "test_dic, test_count = word_count(test_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQbNunyROvWY",
        "outputId": "8bc22360-2a24-4a9d-9c03-0a34c4176327"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1308729\n",
            "764\n"
          ]
        }
      ],
      "source": [
        "print(train_count)\n",
        "print(test_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxJfdInKEOU1"
      },
      "source": [
        "#### 3. Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "t-anzuuuPEVW"
      },
      "outputs": [],
      "source": [
        "from nltk.util import ngrams\n",
        "from nltk import FreqDist\n",
        "import collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KycpHbWCPM2v"
      },
      "outputs": [],
      "source": [
        "def calc_bigram(sentences):\n",
        "  bg_freqdist = FreqDist()\n",
        "  for sentence in sentences:\n",
        "    bigrams = ngrams(sentence,2)\n",
        "    bg_freqdist.update(bigrams)\n",
        "  bigram_dic = {k : v for k,v in collections.Counter(bg_freqdist).most_common()[:]}\n",
        "  return bigram_dic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tfgzUsLSQFfY"
      },
      "outputs": [],
      "source": [
        "train_bigram_dic = calc_bigram(train_sentences)\n",
        "test_bigram_dic = calc_bigram(test_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "71XYcrN3NNOM"
      },
      "outputs": [],
      "source": [
        "v = train_count\n",
        "pbg = 1 / v\n",
        "mu = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TA78fVFILxWn"
      },
      "outputs": [],
      "source": [
        "incomplete_sentences = [\n",
        "     (2 ,'چون مشک سیه بود مرا هر دو'),\n",
        "     (1,'گر خورد سوگند هم آن'),\n",
        "     (1,'زانک نفس آشفته تر گردد از'),\n",
        "     (1,'ازین زشت تر در جهان رنگ'),\n",
        "     (2 ,'دوست در خانه و ما گرد'),\n",
        "     (1,'شب است و شمع و شراب و')]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jemMjYgXQ8s8"
      },
      "outputs": [],
      "source": [
        "def predict_drichlet_prior(sentence):\n",
        "  tokens = sentence.strip().split(' ')\n",
        "  last_word = tokens[-1]\n",
        "  last_word_count = train_dic[last_word]\n",
        "  possible_words = {k: ((v + (mu * pbg))/(last_word_count + mu)) for k,v in train_bigram_dic.items() if k[0] == last_word}\n",
        "  sorted_possible_words = {k:v for k,v in sorted(possible_words.items(), key = lambda item : item[1], reverse = True)}\n",
        "  return list(sorted_possible_words.keys())[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W_zLUPZTyc0",
        "outputId": "b0c0ea72-5cef-406f-ace1-0c9564e9c8da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "چون مشک سیه بود مرا هر دو\n",
            "چون مشک سیه بود مرا هر دو چشم من\n",
            "-------\n",
            "گر خورد سوگند هم آن\n",
            "گر خورد سوگند هم آن را\n",
            "-------\n",
            "زانک نفس آشفته تر گردد از\n",
            "زانک نفس آشفته تر گردد از آن\n",
            "-------\n",
            "ازین زشت تر در جهان رنگ\n",
            "ازین زشت تر در جهان رنگ و\n",
            "-------\n",
            "دوست در خانه و ما گرد\n",
            "دوست در خانه و ما گرد و از\n",
            "-------\n",
            "شب است و شمع و شراب و\n",
            "شب است و شمع و شراب و از\n",
            "-------\n"
          ]
        }
      ],
      "source": [
        "for n,sentence in incomplete_sentences:\n",
        "  print(sentence)\n",
        "\n",
        "  if n > 1 :\n",
        "    for i in range(0, n):\n",
        "      possible_word= predict_drichlet_prior(sentence)\n",
        "      sentence = \" \".join([sentence, possible_word])\n",
        "  else:\n",
        "    possible_word= predict_drichlet_prior(sentence)\n",
        "    sentence = \" \".join([sentence, possible_word])\n",
        "\n",
        "  print(sentence)\n",
        "  print('-------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9xOXzaVakAV"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwAB5ynw03M2"
      },
      "source": [
        "Perplexity of sentence and corpus : https://stats.stackexchange.com/questions/129352/how-to-find-the-perplexity-of-a-corpus#:~:text=As%20you%20said%20in%20your,We%20are%20done.&text=A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3Tl8OWDI04iS"
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WKy4Yn5yrL9C"
      },
      "outputs": [],
      "source": [
        "def drichlet_prior(tokens,corpus_bigram_dic,corpus_unigram_dic,corpus_count):\n",
        "  pbg = 1 / test_count\n",
        "  sent_bigram = ngrams(tokens,2)\n",
        "  prob = corpus_unigram_dic[tokens[0]] / corpus_count\n",
        "  for w1,w2 in sent_bigram:\n",
        "    prob *= ((corpus_bigram_dic.get((w1,w2),0) + (mu * pbg)) / (corpus_unigram_dic[w1] + mu))\n",
        "  return prob   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EeZsQ1FqOfKp"
      },
      "outputs": [],
      "source": [
        "corpus_prob = 0\n",
        "for sentence in test_sentences:\n",
        "  corpus_prob += math.log(drichlet_prior(sentence,test_bigram_dic,test_dic,test_count))\n",
        "perplexity = 2 ** ((-1 / test_count) * corpus_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ7lSDE_1FQ1",
        "outputId": "83a7cb7c-9d6c-4397-9192-f4af57800211"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.1369633871450855"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "perplexity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpzq5RmCapLS"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF6AMh0bDMCC"
      },
      "source": [
        "#### 1. Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ri7un3lE5RSl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from nltk.util import ngrams\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY4Q7uRBCGS-"
      },
      "source": [
        "#### 2. Create sequences based on length of input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "cYqiTYEmatlV"
      },
      "outputs": [],
      "source": [
        "def create_sequence(sentences,nn_input):\n",
        "  seq_length = nn_input + 1\n",
        "  sequences = []\n",
        "  for sen in sentences:\n",
        "    sequence = ngrams(sen,seq_length) \n",
        "    sequences.extend([list(x) for x in sequence])\n",
        "  return sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "fo6_CRPBATBt"
      },
      "outputs": [],
      "source": [
        "train_sequences = create_sequence(train_sentences,2)\n",
        "test_sequences = create_sequence(test_sentences,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fve__1OdAu4P",
        "outputId": "7dee9eb3-92ef-436a-8c94-06a0f2eeb67c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['زانک', 'دل', 'یا']\n",
            "['هل', 'تا', 'نفسی']\n"
          ]
        }
      ],
      "source": [
        "print(train_sequences[0])\n",
        "print(test_sequences[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK91AVTK8o_X",
        "outputId": "1f48649a-b9f5-4a02-ef2b-1a73c39df670"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "930977\n",
            "548\n"
          ]
        }
      ],
      "source": [
        "print(len(train_sequences))\n",
        "print(len(test_sequences))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmnXG5W0CP_m"
      },
      "source": [
        "#### 3. Tokenzing sequences to numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Ug6xhWC99Zy0"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_sequences)\n",
        "tokenizer.fit_on_texts(test_sequences)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_sequences)\n",
        "train_sequences = tokenizer.texts_to_sequences(train_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A26rI41BArGR",
        "outputId": "039ccc34-0aab-46f7-ef46-2db5f0865a1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[973, 17, 104]\n",
            "[3005, 21, 1848]\n"
          ]
        }
      ],
      "source": [
        "print(train_sequences[0])\n",
        "print(test_sequences[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fIyt0CcCf-R",
        "outputId": "86e23169-c1df-4e7a-8fc2-25717c9475e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(930977, 3)\n",
            "(548, 3)\n"
          ]
        }
      ],
      "source": [
        "print(np.shape(train_sequences))\n",
        "print(np.shape(test_sequences))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFKLv8VrCWU9"
      },
      "source": [
        "#### 4. Find out how many unique words we have"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "33pOBaQRB9B1"
      },
      "outputs": [],
      "source": [
        "v_size = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7bqEmG4Cc3O",
        "outputId": "0e1f251c-c360-48df-d6e0-a203377b5d8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "56711\n"
          ]
        }
      ],
      "source": [
        "print(v_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9Jpst9uCwSz"
      },
      "source": [
        "#### 5. Spliting sequences to input and output of neural net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "tVaFe48NEz6a"
      },
      "outputs": [],
      "source": [
        "train_sequences = np.array(train_sequences)\n",
        "test_sequences = np.array(test_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "A_TJURTQC0iY"
      },
      "outputs": [],
      "source": [
        "input_train = train_sequences[:,:2]\n",
        "output_train = train_sequences[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "h_YCNg_SSOj_"
      },
      "outputs": [],
      "source": [
        "input_test = test_sequences[:,:2]\n",
        "output_test = test_sequences[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "823bGNFCFElr",
        "outputId": "309ad8c8-033f-4218-9d4d-949859b11217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(930977, 2)\n",
            "(930977,)\n"
          ]
        }
      ],
      "source": [
        "print(np.shape(input_train))\n",
        "print(np.shape(output_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3v7jDi1FGcd",
        "outputId": "82ead851-59bb-4258-c13f-52395b360f8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(930977, 1)\n"
          ]
        }
      ],
      "source": [
        "output_train = output_train.reshape(-1,1)\n",
        "print(np.shape(output_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUjEzxXHSea7",
        "outputId": "282bf498-6637-46f8-ec3a-3b0443114b28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(548, 2)\n",
            "(548,)\n"
          ]
        }
      ],
      "source": [
        "print(np.shape(input_test))\n",
        "print(np.shape(output_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JpuJs2fSiLc",
        "outputId": "1283a436-dec3-4721-e52b-58173e2e0a82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(548, 1)\n"
          ]
        }
      ],
      "source": [
        "output_test = output_test.reshape(-1,1)\n",
        "print(np.shape(output_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MVz592-FfIg"
      },
      "source": [
        "#### 6. make the output layer the probability distribution of all words using to catagorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "stijp0AXomb-"
      },
      "outputs": [],
      "source": [
        "# We should use yield when we want to iterate over a sequence, but don’t want to store the entire sequence in memory.\n",
        "# This allows its code to produce a series of values over time, rather than computing them at once and sending them back like a list.\n",
        "def generator(X_, y_, batch_size, num_classes):\n",
        "    num_samples = len(X_)\n",
        "    while True: \n",
        "        for offset in range(0, num_samples, batch_size):\n",
        "            X_batch_samples = X_[offset:offset+batch_size]\n",
        "            y_batch_samples = y_[offset:offset+batch_size]\n",
        "            y_batch_samples = to_categorical(y_batch_samples, num_classes)\n",
        "            yield X_batch_samples, y_batch_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "1Z2wk3V3S_U7"
      },
      "outputs": [],
      "source": [
        "# we will lack ram since training set is big\n",
        "# we conver to categorical using batches\n",
        "train_generator = generator(input_train,output_train,2000,v_size)\n",
        "output_test = to_categorical(output_test,num_classes=v_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uza8vjhqpIj3",
        "outputId": "b4dbff63-3bd9-4da8-975b-da4089e4409a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElvQTA8-rymy"
      },
      "source": [
        "#### 7. Model implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "QEJ41AwGsf-5"
      },
      "outputs": [],
      "source": [
        "# sequential is a model\n",
        "from keras.models import Sequential\n",
        "# different type of layers\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Lyy3bIWAr2Nc"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "class plot_loss(keras.callbacks.Callback):\n",
        "  def on_train_begin(self,logs={}):\n",
        "        self.i = 0\n",
        "        self.xs = []\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.fig = plt.figure()\n",
        "        self.logs = []\n",
        "\n",
        "  def on_epoch_end(self,epoch,logs={}):\n",
        "        self.logs.append(logs)\n",
        "        self.xs.append(self.i)\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.i += 1\n",
        "        clear_output(wait=True)\n",
        "        plt.plot(self.xs, self.losses, label=\"loss\")\n",
        "        plt.plot(self.xs, self.val_losses, label=\"val_loss\")\n",
        "        plt.legend()\n",
        "        plt.show();\n",
        "plots = plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "hGHjIBNjsc-X"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "# 50 is length of each word embedding \n",
        "# v_size is range of integer numbers we have (max number we can get as input of embedding)\n",
        "model.add(Embedding(v_size , 50 ,input_length=2 ,name='Embedding-layer'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(int(v_size/2), activation='relu', name='Hidden-layer'))\n",
        "model.add(Dense(v_size,activation='softmax',name='Output-layer'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaxx0EXj0wby",
        "outputId": "bbd7e77d-c03c-4c76-a75a-f87bf53ce8d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Embedding-layer (Embedding)  (None, 2, 50)            2835550   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 100)               0         \n",
            "                                                                 \n",
            " Hidden-layer (Dense)        (None, 28355)             2863855   \n",
            "                                                                 \n",
            " Output-layer (Dense)        (None, 56711)             1608097116\n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,613,796,521\n",
            "Trainable params: 1,613,796,521\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "7rFeqHoG1eYM"
      },
      "outputs": [],
      "source": [
        "#check point saves the best model in a specific address\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/model-{epoch:03d}--{val_accuracy:03f}.h5', verbose=1, monitor='val_loss',save_best_only=True, save_weights_only=True, mode='min')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "uZHJUK1Q2Nqt"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "gVf5fiNP2Qrf",
        "outputId": "ef210fdf-51ab-4836-bc38-ccde9425d139"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10: val_loss did not improve from 6.93360\n",
            "465/465 [==============================] - 235s 506ms/step - loss: 2.1421 - accuracy: 0.4850 - val_loss: 11.3451 - val_accuracy: 0.0766\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1116d94d90>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_generator, batch_size=1000, epochs=10, steps_per_epoch=(len(train_sequences)//1000), validation_data=(input_test,output_test), callbacks=[plots,checkpoint])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld7LGJBm3ygE"
      },
      "source": [
        "#### 8. Testing model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "QFrgEq5qmtAr"
      },
      "outputs": [],
      "source": [
        "best_model_path = '/content/drive/MyDrive/model-001--0.082117.h5'\n",
        "model.load_weights(best_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "an44FiFNyzur"
      },
      "outputs": [],
      "source": [
        "# return word corresponding to input number\n",
        "def convert_ID_to_word(ID):  \n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if np.int64(index) == ID:\n",
        "      return word\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "LjiM4b04y2cQ"
      },
      "outputs": [],
      "source": [
        "# create sentences from corresponding ids\n",
        "def get_sentence_from_IDs(x):\n",
        "  sent = ''\n",
        "  for elem in x:\n",
        "    sent += convert_ID_to_word(elem) + ' '\n",
        "  return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "V5wrzfFjzRSM"
      },
      "outputs": [],
      "source": [
        "sentences = ['چون مشک سیه بود مرا هر دو',\n",
        " 'گر خورد سوگند هم آن',\n",
        " 'زانک نفس آشفته تر گردد از',\n",
        " 'ازین زشت تر در جهان رنگ',\n",
        " 'دوست در خانه و ما گرد',\n",
        " 'شب است و شمع و شراب و']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Alafe_p-1VCN"
      },
      "outputs": [],
      "source": [
        "sentences_encodeed = tokenizer.texts_to_sequences(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "nnotGFxx1izw"
      },
      "outputs": [],
      "source": [
        "# for sentences with one gap\n",
        "X_test = np.array([sent[-2:] for sent in sentences_encodeed])\n",
        "word_output = model.predict(X_test)\n",
        "word_output = np.argmax(word_output, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp1zBpMX1pbq",
        "outputId": "8f973e62-4ea5-46c0-c2eb-b5d4ba543a3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 7,  7, 10,  1,  6, 14])"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "vkc1dUyw4JXC"
      },
      "outputs": [],
      "source": [
        "# for sentences with two gaps\n",
        "w1 = np.array([sent[-1:] for sent in sentences_encodeed])\n",
        "w2 = word_output\n",
        "X_test = np.column_stack((w1, w2))\n",
        "two_word_prediction = model.predict(X_test)\n",
        "two_word_prediction = np.argmax(two_word_prediction, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1XM3ajF4SXs",
        "outputId": "69465973-4e11-44f6-a9dd-1c4f9131ede6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "چون مشک سیه بود مرا هر دو را به\n",
            "گر خورد سوگند هم آن را\n",
            "زانک نفس آشفته تر گردد از آن\n",
            "ازین زشت تر در جهان رنگ و\n",
            "دوست در خانه و ما گرد تو بر\n",
            "شب است و شمع و شراب و می\n",
            "\n"
          ]
        }
      ],
      "source": [
        "output = ''\n",
        "for i in range(len(sentences)):\n",
        "  output += sentences[i] + ' ' + convert_ID_to_word(word_output[i])\n",
        "  if (i == 0 or i == 4):\n",
        "    output += ' ' + convert_ID_to_word(two_word_prediction[i])\n",
        "  output += '\\n'\n",
        "print(output)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ulKSVXtrI1BI",
        "d58dLCZ0I35I",
        "6T67ohI8LyYB",
        "w9xOXzaVakAV",
        "eF6AMh0bDMCC",
        "NY4Q7uRBCGS-",
        "VmnXG5W0CP_m",
        "jFKLv8VrCWU9"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
